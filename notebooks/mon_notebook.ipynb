{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aca2440c-a24c-4ae9-b4e6-b0c4adf6185f",
   "metadata": {},
   "source": [
    "# DISCLAIMER\n",
    "\n",
    "Due to the end of the free trial of Gcloud when i was running some parts of the notebook. I could not complete it entirely as I would have loved to. I'm sorry for that. Instead, try to run it on your own computer. I hope it will work well. It's really frustrating, after all these hours, not to be able to deliver the work I wanted to. But it seems that I have no choice. I have already gave several dozens of hours trying to make it work it out. I'm disappointed but I can't give it much more time. \n",
    "Note that I made some modifications to the test set that seems to destroy the meaning of the RMSE (since I got some 0.44 instead of 4.5). However, I think that's because I deleted the pickup lat/long values outside of NYC, this reduced greatly the test set and improved a lot performances. I think we shouldn't do it in order to keep our model as general as possible. However, our last model produce a 79% accuracy, which seemes pretty good. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5080c7e1",
   "metadata": {},
   "source": [
    "# Welcome to the DE SDD Evaluation!\n",
    "\n",
    "Today, the goal is to understand how a distributed system can be useful when dealing with medium to large scale data sets.  \n",
    "We'll see that Dask start to be nice as soon as the Data we need to process doesn't quite fit in memory, but also if we\n",
    "need to launch several computations in parallel.\n",
    "\n",
    "In this evaluation, you will:\n",
    "- Use Dask to read and understand the several gigabytes input dataset in a interactive way,\n",
    "- Preprocess the data in a distributed way: cleaning it up and adding some useful features,\n",
    "- Launch some model training that can be parallelized on a big dataset,\n",
    "- Reduce the dataset and train more accurate models on less Data,\n",
    "- Do an hyper parameter search to find the best model on a small sample of Data.\n",
    "\n",
    "In order to run and fill this notebook, you'll need to first deploy a Dask enabled Kubernetes cluster as seen before. So please use the Kubernetes_DaskHub notebook for the steps to do it.\n",
    "\n",
    "Once the Jupyterhub is up, you can clone the DE repository from a Jupyterlab terminal to get this notebook, and select the default kernel.\n",
    "```\n",
    "git clone https://github.com/SupaeroDataScience/DE.git\n",
    "cd DE/notebooks\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9f615b",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "It is some statistics about NY Taxi cabs. \n",
    "\n",
    "See https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/overview, or https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data.\n",
    "        \n",
    "The goal of this evaluation will be to generate a model using machine learning algorithms that will predict the fare amount\n",
    "of a taxi ride given the other input parameters we have.\n",
    "\n",
    "The model will be evaluated using the Root mean squared error algorithm:  \n",
    "https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/overview/evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255611eb",
   "metadata": {},
   "source": [
    "## Try to analyze the Data using Kaggles' start-up code\n",
    "\n",
    "As an introduction, we'll use Kaggle starters' code to get some insights on the data set and\n",
    "computations we'll do and measure pandas library (non parallelized access and process) performance.\n",
    "\n",
    "See https://www.kaggle.com/dster/nyc-taxi-fare-starter-kernel-simple-linear-model where this comes from.\n",
    "\n",
    "This Kaggle method will set the bar to beat with our own tools. I'm sure you can do it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61175e73",
   "metadata": {},
   "source": [
    "#### Reading the data with pandas\n",
    "\n",
    "We're reading only about 20% from the whole data set. Using the storage_options kwarg was mandatory for me to avoid auth issues, don't forget it when you read public data from cloud storage during this evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6a9896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.3 s, sys: 4.72 s, total: 30 s\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "key                   object\n",
       "fare_amount          float64\n",
       "pickup_datetime       object\n",
       "pickup_longitude     float64\n",
       "pickup_latitude      float64\n",
       "dropoff_longitude    float64\n",
       "dropoff_latitude     float64\n",
       "passenger_count        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "train_df =  pd.read_csv('gs://obd-dask23/train.csv', nrows = 10_000_000, storage_options={'token': 'anon'})\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df98a8b",
   "metadata": {},
   "source": [
    "#### Analysing dataset, adding some features and droping null values\n",
    "\n",
    "Let's see if we can see some correlation between passengers count and fare amount?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f584bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 190 ms, sys: 37.1 ms, total: 227 ms\n",
      "Wall time: 224 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "passenger_count\n",
       "0       9.047261\n",
       "1      11.216596\n",
       "2      11.800345\n",
       "3      11.536788\n",
       "4      11.754418\n",
       "5      11.218924\n",
       "6      12.141258\n",
       "7      36.582500\n",
       "8      32.665000\n",
       "9      37.366667\n",
       "34     13.300000\n",
       "51      9.300000\n",
       "129     8.500000\n",
       "208    11.140000\n",
       "Name: fare_amount, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_df.groupby(train_df.passenger_count).fare_amount.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6623ecc",
   "metadata": {},
   "source": [
    "Maybe adding some features about the distance of the trip could be a good idea?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b70ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 95.4 ms, sys: 92.1 ms, total: 187 ms\n",
      "Wall time: 187 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 'abs_diff_longitude' 'abs_diff_latitude' reprensenting the \"Manhattan vector\" from\n",
    "# the pickup location to the dropoff location.\n",
    "def add_travel_vector_features(df):\n",
    "    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n",
    "    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n",
    "\n",
    "add_travel_vector_features(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8c6ca0",
   "metadata": {},
   "source": [
    "Are there some undefined values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01248590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key                    0\n",
      "fare_amount            0\n",
      "pickup_datetime        0\n",
      "pickup_longitude       0\n",
      "pickup_latitude        0\n",
      "dropoff_longitude     74\n",
      "dropoff_latitude      74\n",
      "passenger_count        0\n",
      "abs_diff_longitude    74\n",
      "abs_diff_latitude     74\n",
      "dtype: int64\n",
      "CPU times: user 954 ms, sys: 38.4 ms, total: 992 ms\n",
      "Wall time: 990 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ec78ab",
   "metadata": {},
   "source": [
    "We want to get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bcb7f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old size: 10000000\n",
      "New size: 9999926\n",
      "CPU times: user 1.66 s, sys: 326 ms, total: 1.98 s\n",
      "Wall time: 1.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Old size: %d' % len(train_df))\n",
    "train_df = train_df.dropna(how = 'any', axis = 'rows')\n",
    "print('New size: %d' % len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc2cd37",
   "metadata": {},
   "source": [
    "#### Quick analyze on new features and clean outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c501c429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.09 s, sys: 72.4 ms, total: 1.16 s\n",
      "Wall time: 1.73 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "plot = train_df.iloc[:2000].plot.scatter('abs_diff_longitude', 'abs_diff_latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1a641",
   "metadata": {},
   "source": [
    "70 degrees longitude seems a bit too high..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ac95e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old size: 9999926\n",
      "New size: 9979189\n",
      "CPU times: user 612 ms, sys: 368 ms, total: 979 ms\n",
      "Wall time: 977 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Old size: %d' % len(train_df))\n",
    "train_df = train_df[(train_df.abs_diff_longitude < 5.0) & (train_df.abs_diff_latitude < 5.0)]\n",
    "print('New size: %d' % len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3a4eea",
   "metadata": {},
   "source": [
    "#### Get training features and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1ca5802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9979189, 3)\n",
      "(9979189,)\n",
      "CPU times: user 98.6 ms, sys: 194 ms, total: 293 ms\n",
      "Wall time: 291 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "\n",
    "# using the travel vector, plus a 1.0 for a constant bias term.\n",
    "def get_input_matrix(df):\n",
    "    return np.column_stack((df.abs_diff_longitude, df.abs_diff_latitude, np.ones(len(df))))\n",
    "\n",
    "train_X = get_input_matrix(train_df)\n",
    "train_y = np.array(train_df['fare_amount'])\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836ce60e",
   "metadata": {},
   "source": [
    "#### Train a simple linear model using Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4d698bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148.48697     74.73346376   6.41299165]\n",
      "CPU times: user 836 ms, sys: 682 ms, total: 1.52 s\n",
      "Wall time: 774 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The lstsq function returns several things, and we only care about the actual weight vector w.\n",
    "(w, _, _, _) = np.linalg.lstsq(train_X, train_y, rcond = None)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b46de57",
   "metadata": {},
   "source": [
    "#### Make prediction on our test set and measure performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cab29b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0              int64\n",
       "key                    object\n",
       "fare_amount           float64\n",
       "pickup_datetime        object\n",
       "pickup_longitude      float64\n",
       "pickup_latitude       float64\n",
       "dropoff_longitude     float64\n",
       "dropoff_latitude      float64\n",
       "passenger_count         int64\n",
       "abs_diff_longitude    float64\n",
       "abs_diff_latitude     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df =  pd.read_csv('gs://obd-dask23/test_cleaned.csv', storage_options={'token': 'anon'})\n",
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6c9d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_travel_vector_features(test_df)\n",
    "test_X = get_input_matrix(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5cf989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_predictions = np.matmul(test_X, w).round(decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83a1d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_ref = test_df.fare_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b22f5728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.428124794105603"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(test_y_ref, test_y_predictions, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c732df4",
   "metadata": {},
   "source": [
    "You should get sabout 6.43 of RMSE, not bad, but we can do better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78fdd59",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "### Some questions on this first Analysis\n",
    "\n",
    "- What is the most expensive part of the analysis, the one that takes the most time (see the %%time we used above)?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea301550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataframe with pandas was the most expensive part of this analysis, since it lasted about 46 seconds (wall time, and 35 seconds on CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e331b7",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Try to load the whole dataset with Pandas and comment what happens. Can you explain why?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42190bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#train_df =  pd.read_csv('gs://obd-dask23/train.csv', storage_options={'token': 'anon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a22544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The input data is just too big to fit inside memory. That is why our kernel crashed.\n",
    "#I commented the line above to avoid another crash by accident"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f478f17c",
   "metadata": {},
   "source": [
    "# Processing our data set using Dask\n",
    "\n",
    "Dask will help us process all the input data set at once. It is really useful when input data is too big to fit in memory. In this case, it can stream the computation by data chunks on one computer, or distribute the computation on several computers.\n",
    "\n",
    "This is what we'll do next!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c22aeb",
   "metadata": {},
   "source": [
    "### Start an appropriately sized Dask cluster for our analysis\n",
    "\n",
    "We'll need a Dask cluster to pre process the data and distribute some learning, the following code starts one in our K8S infrastructure.\n",
    "\n",
    "**Be sure to have any other Dask cluster shutdown.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62d7d4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_gateway import Gateway\n",
    "gateway = Gateway()\n",
    "clusters=gateway.list_clusters()\n",
    "for cluster in clusters:\n",
    "    gateway.stop_cluster(cluster.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f18fc8-fa16-490f-9a39-033d1829ead7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300f99baa14c4e2890d4314c9b76e4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>GatewayCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n<style scoped>\\n    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster = gateway.new_cluster(worker_cores=1, worker_memory=3.0)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a329c1",
   "metadata": {},
   "source": [
    "__Please click on the Dashboard link above, it will help you a lot!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f38dac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f33cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992aba71",
   "metadata": {},
   "source": [
    "### Launch some computation, what about Pi?\n",
    "\n",
    "Just to check our cluster is working!\n",
    "\n",
    "We'll use Dask array, a Numpy extension for this, we'll also use it later on for the Machine Learning part of this evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "893cedb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi ~= 3.1415999876\n",
      "CPU times: user 807 ms, sys: 119 ms, total: 927 ms\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import dask.array as da\n",
    "\n",
    "sample = 10_000_000_000  # <- this is huge!\n",
    "xxyy = da.random.uniform(-1, 1, size=(2, sample))\n",
    "norm = da.linalg.norm(xxyy, axis=0)\n",
    "summ = da.sum(norm <= 1)\n",
    "insiders = summ.compute()\n",
    "pi = 4 * insiders / sample\n",
    "print(\"pi ~= {}\".format(pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc0fd7e",
   "metadata": {},
   "source": [
    "## Now, access the data of our BE using Dask\n",
    "\n",
    "We'll use Dask Dataframe, a distributed version of Pandas Dataframe.\n",
    "\n",
    "Remember, Dask shares the same API as Pandas.\n",
    "\n",
    "See https://docs.dask.org/en/latest/dataframe.html.\n",
    "\n",
    "<br>\n",
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "So instead of using Pandas to load the dataset, just use the equivalent dask method from dask.dataframe.\n",
    "\n",
    "- Fill the following cell (the second one) with the appropriate code to read the data using Dask.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e2fe6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6905e21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 429 ms, sys: 34.3 ms, total: 463 ms\n",
      "Wall time: 660 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df=dd.read_csv('gs://obd-dask23/train.csv', storage_options={'token': 'anon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "178c1003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=89</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>string</td>\n",
       "      <td>float64</td>\n",
       "      <td>string</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: to_pyarrow_string, 2 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                   key fare_amount pickup_datetime pickup_longitude pickup_latitude dropoff_longitude dropoff_latitude passenger_count\n",
       "npartitions=89                                                                                                                        \n",
       "                string     float64          string          float64         float64           float64          float64           int64\n",
       "                   ...         ...             ...              ...             ...               ...              ...             ...\n",
       "...                ...         ...             ...              ...             ...               ...              ...             ...\n",
       "                   ...         ...             ...              ...             ...               ...              ...             ...\n",
       "                   ...         ...             ...              ...             ...               ...              ...             ...\n",
       "Dask Name: to_pyarrow_string, 2 graph layers"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c5362",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "### Some questions about this data loading\n",
    "\n",
    "- That was fast for several gigabytes, wasn't it? Why is this, did we really load all the data?\n",
    "- Why the returned dataframe looks empty?\n",
    "- See the number of partitions described above? What does it correspond to? (hint, look at the blocksize parameter from https://docs.dask.org/en/latest/generated/dask.dataframe.read_csv.html). You might also get a more precise idea of what this number corresponds to with the next code execution.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a933388-9149-4720-afb7-853ab75c67b7",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "Dask adopt a lazy evaluation model. It means that when you load data into a Daska df, Daks doesn't immediately load the data into memory. Instead, it creates a task graph that describes the operation needed to load the data. The graph is only executer when you explicitly ask for the result of a computation (by calling .compute()). That's why the dataframe look empty. In a sense however, we really loaded the data, since Dask has prepared a plan to load the data when needed. But no in the sense that the data is not yet in memory. The loading only happens when necessary during computation.\n",
    "\n",
    "When we have loaded our data into a Dask df, it got divided into smaller partitions (chunks), each corresponding to a block of data. These partitions allow Dask to parallelize computations accross the dataset, making it suitable for distributed and out-of-core processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6834c674",
   "metadata": {},
   "source": [
    "## Little warm up: Analyzing our data to better understand it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc8f8e",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "- First, how many records do we have? (hint, in python, len() works for almost any object).\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eff99939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 120 ms, sys: 15.2 ms, total: 135 ms\n",
      "Wall time: 2min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55413856"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "len(train_df)\n",
    "#It looks like we have 55 413 856 records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1980192c",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- What did happend when counting record of our Dask dataframe (as opposed to with only the `read_csv` call? Remember with the Spark tutorial: transformations and actions... Same kind of concepts exist in Dask. Just look at the Dask Dashboard!\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8fd5c5-3def-4638-bac6-5fc765585bce",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "When you count the number of records in a Dask DataFrame, you're moving beyond just setting up a computation (as with the read_csv call) and actually triggering the computation to run. This distinction between setting up computations and executing them is indeed similar to the concept of transformations and actions in Spark. In Dask, this is often referred to as the difference between lazy evaluation and eager execution. \n",
    "\n",
    "**Transformations** are operations that don't compute results immediately, but instead build up a task graph (like we did when calling read_csv, but also filtering, grouping...). These operations are lazy, like we previously explained, because they don't trigger any actual data processing, they just prepare the computation plan.\n",
    "\n",
    "**Actions** are operations that trigger computation and produce results (such as .compute()). When performing actions in Dask, it executes the task graph previously built by the transformation and then actually process the data.\n",
    "\n",
    "Looking at our dashboard, we see that calling len(train_df) did load the necessary data into memory, processing it in partitions to keep memory usage manageable, then executing the taks graph, then aggregating the count results of the different parts (this operation is also part of the task graph), and finally returning the result (the number of record in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668942d8",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Compare the time of this computation to the time of loading a subset of the Dataset with Pandas. Was it fast enough considering the number of workers we have?\n",
    "    \n",
    "I recommend trying to calculate an estimation of the time it would take with Pandas to read the entire dataset, and **total processing** time (not only the walltime) it took for every dask workers.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2025840-3ce6-4c2e-a689-2a76347bc680",
   "metadata": {},
   "source": [
    "**ANSWER** \n",
    "\n",
    "In order to load 20% of the dataset earlier, it took us about 45 seconds with walltime. If we multiply it by 5, we estimate it would have taken us 225 seconds, or 3.75 minutes to load the full dataset.\n",
    "For the Dask dataset, we look at the total processing time (summing user and sys), which brings us to 60s. We used 10 workers. Theoretically, this operation should execute in 225/10=25 seconds, but that did not happen. Why ? Because of what is called *Overhead*, meaning the theoretical perfect speed-up is never attained because of task scheduling, data partitioning, aggregating and communication between workers.\n",
    "Even if we did not speed-up the computation by a factor 10, we did it with a factor 2, which is still pretty good. Maybe we could have increased a little bit the number of worker to improve performance (but this is not sure). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e0f615",
   "metadata": {},
   "source": [
    "Let's have a look at some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cba28ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 ms, sys: 1.32 ms, total: 12.3 ms\n",
      "Wall time: 3.02 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-10-12 23:47:39.0000002</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2014-10-12 23:47:39 UTC</td>\n",
       "      <td>-73.973863</td>\n",
       "      <td>40.764248</td>\n",
       "      <td>-73.986874</td>\n",
       "      <td>40.736618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-08-17 22:34:00.000000118</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2012-08-17 22:34:00 UTC</td>\n",
       "      <td>-73.997062</td>\n",
       "      <td>40.722330</td>\n",
       "      <td>-73.997642</td>\n",
       "      <td>40.729135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-05-17 13:11:00.000000229</td>\n",
       "      <td>9.70</td>\n",
       "      <td>2011-05-17 13:11:00 UTC</td>\n",
       "      <td>-74.000002</td>\n",
       "      <td>40.727167</td>\n",
       "      <td>-73.984253</td>\n",
       "      <td>40.753135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-08 09:10:25.0000005</td>\n",
       "      <td>57.33</td>\n",
       "      <td>2015-03-08 09:10:25 UTC</td>\n",
       "      <td>-74.004166</td>\n",
       "      <td>40.737652</td>\n",
       "      <td>-73.795753</td>\n",
       "      <td>40.644497</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-27 19:54:44.0000001</td>\n",
       "      <td>7.30</td>\n",
       "      <td>2010-03-27 19:54:44 UTC</td>\n",
       "      <td>-73.990309</td>\n",
       "      <td>40.751309</td>\n",
       "      <td>-73.980597</td>\n",
       "      <td>40.761481</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             key  fare_amount          pickup_datetime  \\\n",
       "0    2014-10-12 23:47:39.0000002         9.00  2014-10-12 23:47:39 UTC   \n",
       "1  2012-08-17 22:34:00.000000118         4.10  2012-08-17 22:34:00 UTC   \n",
       "2  2011-05-17 13:11:00.000000229         9.70  2011-05-17 13:11:00 UTC   \n",
       "3    2015-03-08 09:10:25.0000005        57.33  2015-03-08 09:10:25 UTC   \n",
       "4    2010-03-27 19:54:44.0000001         7.30  2010-03-27 19:54:44 UTC   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.973863        40.764248         -73.986874         40.736618   \n",
       "1        -73.997062        40.722330         -73.997642         40.729135   \n",
       "2        -74.000002        40.727167         -73.984253         40.753135   \n",
       "3        -74.004166        40.737652         -73.795753         40.644497   \n",
       "4        -73.990309        40.751309         -73.980597         40.761481   \n",
       "\n",
       "   passenger_count  \n",
       "0                1  \n",
       "1                1  \n",
       "2                2  \n",
       "3                2  \n",
       "4                1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84867e4",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Why was it faster than counting all the records above? \n",
    "- What did we actualy read? You might want to look at the Dashboard for some hinsights. Remember that Dask laziness is not only about transformations and actions, but optimizing the computations needed.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c852e0-41d8-41e5-9b41-989cc96ed932",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "It was much faster than counting all the records ! When looking at the dashboard, we can see that only one worker was called with a to_pyarrow_string task. It is a method known to convert different objects (such as ou dataset first 5 rows) into string in a noticable really fast why. This method was probably chosen on purpose in order to accelerate the computation, highlighting the optimization of computation at all levels. When looking at this task into details, we notice that in the end, strings ar finally casted back to their original type with the .astype() method.\n",
    "Also, it is pretty clear that loading only the first five lines of the dataset should be much faster than crawling all its records like the len() method forced us to do. We took advantage of the partition into chunks in order to optimize computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81342f11",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Let's compute the mean of the fare amount given the passengers count, **as we've done with Pandas above**. Please fill the blank. (hint: Dask is the same as pandas, but often with a `compute()` call at the end)\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c56ddf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 78.1 ms, sys: 10.7 ms, total: 88.7 ms\n",
      "Wall time: 1min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "passenger_count\n",
       "0       9.015400\n",
       "1      11.216398\n",
       "2      11.838426\n",
       "3      11.540684\n",
       "4      11.766121\n",
       "5      11.208482\n",
       "6      12.126306\n",
       "8      29.981111\n",
       "208     8.975000\n",
       "51      9.300000\n",
       "129     8.900000\n",
       "7      31.788667\n",
       "9      36.993043\n",
       "34     13.300000\n",
       "49      2.500000\n",
       "Name: fare_amount, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_df.groupby(train_df.passenger_count).fare_amount.mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121f1dbf",
   "metadata": {},
   "source": [
    "Wow, ever seen a cab with more than **200 people**?? Americans are crazy. And it's cheap...\n",
    "\n",
    "<br>\n",
    "\n",
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "- This computation is slow, especially compared with Pandas, why? (Look a the Dashboard, again).\n",
    "- Which part of the computation is slow, look at the Dashboard to see the name of the tasks. Hint, this is the same as Pandas.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c2e0d9-5aed-44da-b3b5-65e433a8c647",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "Dask breaks down computation into tasks that can be executed in parallel. However, scheduling and managing these tasks introduce overhead (as we specified before). For operations that are not highly compute-intensive, the overhead of task management can outweight the benefits of parallel execution. There's an inherent cost in moving data between worked, this is particularly important for group-by operations, which may require significant data shuffling to group records by keys before computing the mean. Pandas operates in-memory and is highly optimized for single-threaded performance. For datasets that fit into memory, Pandas can often perform computations like group-by and mean very quickly. The simplicity of operating in a single process without the need to manage parallel tasks or handle data distribution can make Pandas faster for these types of operations.\n",
    "\n",
    "When looking at the dashboard, our hypothese is confirmed : the worst-performing (taking longer) task is the .getItem() method. The groupby-count-chunk and groupby-sum-chunk did only take 2 seconds, while the getItem did take 272 seconds (partitionned between all workers). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff37ce7",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- How could we optimize the next computations, using which Dask method? Same as Spark...\n",
    "- Where will be the data at the end of the computation triggered by this call?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c314cb9-1293-4aec-bd81-27e376c62419",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "To optimize computations in Dask, especially for operations executed repeatedly, or requiring significant data shuffling ( such as group-by), we can use the persist method. This approach is similar to what we did previously with Spark, and can significantly improve performance for iterative computation or when needing to access the same dataset multiple times. \n",
    "The persist method evaluates the computation up to the current point, and keeps the resulting dataset in memory (or on disk) accross the cluster. After calling persist, the dataset will be kept in distributed memory accross the cluster's workers, and subsequent operations (transformations, actions), will be much faster. Any future computation of the persisted data will start from the in-memory state of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "26f10c20-82ec-49d9-a16e-a7353a506cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=dd.read_csv('gs://obd-dask23/train.csv', storage_options={'token': 'anon'}).persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49397217",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Look at the Dashboard at what is happening beind the scene.\n",
    "    \n",
    "Wait for the end of this call on the Dashboard, then try again the previous computation on fare_amout.mean():\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a9fa8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 78.5 ms, sys: 9.56 ms, total: 88 ms\n",
      "Wall time: 28.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "passenger_count\n",
       "0       9.015400\n",
       "1      11.216398\n",
       "2      11.838426\n",
       "3      11.540684\n",
       "4      11.766121\n",
       "5      11.208482\n",
       "6      12.126306\n",
       "8      29.981111\n",
       "208     8.975000\n",
       "51      9.300000\n",
       "129     8.900000\n",
       "7      31.788667\n",
       "9      36.993043\n",
       "34     13.300000\n",
       "49      2.500000\n",
       "Name: fare_amount, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_df.groupby(train_df.passenger_count).fare_amount.mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddadf8d3",
   "metadata": {},
   "source": [
    "Much better isn't it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bf8179",
   "metadata": {},
   "source": [
    "## Let's do some preprocessing of our data to clean it up and add some features\n",
    "\n",
    "<br>\n",
    "\n",
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "- You'll need to do the same operations as in pandas, we just need to call compute when needing a result, and not compute when building our dataframe transformations.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adffd39",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "#### Cleaning up\n",
    "\n",
    "- Is there some null values in our data?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fbea246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key                    0\n",
      "fare_amount            0\n",
      "pickup_datetime        0\n",
      "pickup_longitude       0\n",
      "pickup_latitude        0\n",
      "dropoff_longitude    376\n",
      "dropoff_latitude     376\n",
      "passenger_count        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50fd4c3",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Yep! We must get rid of them...\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c2ff9453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.74 ms, sys: 1.92 ms, total: 9.66 ms\n",
      "Wall time: 8.64 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = train_df.dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a8379f88-43cd-459b-9aa4-5aea332c2931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key                  0\n",
      "fare_amount          0\n",
      "pickup_datetime      0\n",
      "pickup_longitude     0\n",
      "pickup_latitude      0\n",
      "dropoff_longitude    0\n",
      "dropoff_latitude     0\n",
      "passenger_count      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a1f1b5",
   "metadata": {},
   "source": [
    "#### Adding features\n",
    "\n",
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "- As with Pandas above, add the latitude and longitude distance vector with a function call\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9a108c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Answer needed here. We define a function here, cause we'll need to apply it on our test dataframe too later on!\n",
    "def add_travel_vector_features(df):\n",
    "    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n",
    "    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n",
    "add_travel_vector_features(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162dafb7",
   "metadata": {},
   "source": [
    "A quick look at our Dataframe to check things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13573f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>abs_diff_longitude</th>\n",
       "      <th>abs_diff_latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-10-12 23:47:39.0000002</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2014-10-12 23:47:39 UTC</td>\n",
       "      <td>-73.973863</td>\n",
       "      <td>40.764248</td>\n",
       "      <td>-73.986874</td>\n",
       "      <td>40.736618</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013011</td>\n",
       "      <td>0.027630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-08-17 22:34:00.000000118</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2012-08-17 22:34:00 UTC</td>\n",
       "      <td>-73.997062</td>\n",
       "      <td>40.722330</td>\n",
       "      <td>-73.997642</td>\n",
       "      <td>40.729135</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.006805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-05-17 13:11:00.000000229</td>\n",
       "      <td>9.70</td>\n",
       "      <td>2011-05-17 13:11:00 UTC</td>\n",
       "      <td>-74.000002</td>\n",
       "      <td>40.727167</td>\n",
       "      <td>-73.984253</td>\n",
       "      <td>40.753135</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015749</td>\n",
       "      <td>0.025968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-08 09:10:25.0000005</td>\n",
       "      <td>57.33</td>\n",
       "      <td>2015-03-08 09:10:25 UTC</td>\n",
       "      <td>-74.004166</td>\n",
       "      <td>40.737652</td>\n",
       "      <td>-73.795753</td>\n",
       "      <td>40.644497</td>\n",
       "      <td>2</td>\n",
       "      <td>0.208412</td>\n",
       "      <td>0.093155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-27 19:54:44.0000001</td>\n",
       "      <td>7.30</td>\n",
       "      <td>2010-03-27 19:54:44 UTC</td>\n",
       "      <td>-73.990309</td>\n",
       "      <td>40.751309</td>\n",
       "      <td>-73.980597</td>\n",
       "      <td>40.761481</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009712</td>\n",
       "      <td>0.010172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             key  fare_amount          pickup_datetime  \\\n",
       "0    2014-10-12 23:47:39.0000002         9.00  2014-10-12 23:47:39 UTC   \n",
       "1  2012-08-17 22:34:00.000000118         4.10  2012-08-17 22:34:00 UTC   \n",
       "2  2011-05-17 13:11:00.000000229         9.70  2011-05-17 13:11:00 UTC   \n",
       "3    2015-03-08 09:10:25.0000005        57.33  2015-03-08 09:10:25 UTC   \n",
       "4    2010-03-27 19:54:44.0000001         7.30  2010-03-27 19:54:44 UTC   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.973863        40.764248         -73.986874         40.736618   \n",
       "1        -73.997062        40.722330         -73.997642         40.729135   \n",
       "2        -74.000002        40.727167         -73.984253         40.753135   \n",
       "3        -74.004166        40.737652         -73.795753         40.644497   \n",
       "4        -73.990309        40.751309         -73.980597         40.761481   \n",
       "\n",
       "   passenger_count  abs_diff_longitude  abs_diff_latitude  \n",
       "0                1            0.013011           0.027630  \n",
       "1                1            0.000580           0.006805  \n",
       "2                2            0.015749           0.025968  \n",
       "3                2            0.208412           0.093155  \n",
       "4                1            0.009712           0.010172  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7cfc5f",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Now let's quickly plot a subset of our travel vector features to see its distribution. Use dask.dataframe.sample() to get about 1 percent of the rows, and get it back with compute and plot as we've done it with Pandas\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09f457c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 6.44 µs\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%time\n",
    "\n",
    "# Sample approximately 1% of the data\n",
    "sampled_df = train_df.sample(frac=0.01).compute()\n",
    "\n",
    "plot = sampled_df.plot.scatter('abs_diff_longitude', 'abs_diff_latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36182399",
   "metadata": {},
   "source": [
    "Wow, looks like we have some strange values here: more than 1000° of distance... There's a problem somewhere.\n",
    "\n",
    "<br>\n",
    "\n",
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "- Just get rid of the extreme values, we should keep only values inside the city wall or so. Like with Pandas above...\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3e3286a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.74 ms, sys: 60 µs, total: 4.8 ms\n",
      "Wall time: 4.63 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_df = train_df[(train_df.abs_diff_longitude < 5) & (train_df.abs_diff_latitude < 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfc1f4a",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "- you can do another plot like above with the filtered values if you like.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45edd5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampled_df = train_df.sample(frac=0.01).compute()\n",
    "\n",
    "plot = sampled_df.plot.scatter('abs_diff_longitude', 'abs_diff_latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a525ada",
   "metadata": {},
   "source": [
    "Ok, let's see some statistics on our Dataset. The describe() function inherited from Pandas compute a lot of statistics on a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d49070ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>abs_diff_longitude</th>\n",
       "      <th>abs_diff_latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.529894e+07</td>\n",
       "      <td>5.529894e+07</td>\n",
       "      <td>5.529894e+07</td>\n",
       "      <td>5.529894e+07</td>\n",
       "      <td>5.529894e+07</td>\n",
       "      <td>5.529894e+07</td>\n",
       "      <td>5.529894e+07</td>\n",
       "      <td>5.529894e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.133683e+01</td>\n",
       "      <td>-7.257290e+01</td>\n",
       "      <td>3.995280e+01</td>\n",
       "      <td>-7.257205e+01</td>\n",
       "      <td>3.995314e+01</td>\n",
       "      <td>1.685440e+00</td>\n",
       "      <td>2.251316e-02</td>\n",
       "      <td>2.110157e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.071499e+01</td>\n",
       "      <td>1.094742e+01</td>\n",
       "      <td>7.044005e+00</td>\n",
       "      <td>1.094731e+01</td>\n",
       "      <td>7.044055e+00</td>\n",
       "      <td>1.326790e+00</td>\n",
       "      <td>3.854502e-02</td>\n",
       "      <td>2.903143e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.000000e+02</td>\n",
       "      <td>-3.440696e+03</td>\n",
       "      <td>-3.488080e+03</td>\n",
       "      <td>-3.440696e+03</td>\n",
       "      <td>-3.488080e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>-7.399201e+01</td>\n",
       "      <td>4.073514e+01</td>\n",
       "      <td>-7.399136e+01</td>\n",
       "      <td>4.073421e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.827000e-03</td>\n",
       "      <td>6.606000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.500000e+00</td>\n",
       "      <td>-7.398174e+01</td>\n",
       "      <td>4.075281e+01</td>\n",
       "      <td>-7.398010e+01</td>\n",
       "      <td>4.075332e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.244900e-02</td>\n",
       "      <td>1.387000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.250000e+01</td>\n",
       "      <td>-7.396703e+01</td>\n",
       "      <td>4.076725e+01</td>\n",
       "      <td>-7.396365e+01</td>\n",
       "      <td>4.076821e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.370300e-02</td>\n",
       "      <td>2.697000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.396336e+04</td>\n",
       "      <td>3.456223e+03</td>\n",
       "      <td>3.378013e+03</td>\n",
       "      <td>3.456223e+03</td>\n",
       "      <td>3.378013e+03</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>4.989833e+00</td>\n",
       "      <td>4.991325e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "count  5.529894e+07      5.529894e+07     5.529894e+07       5.529894e+07   \n",
       "mean   1.133683e+01     -7.257290e+01     3.995280e+01      -7.257205e+01   \n",
       "std    2.071499e+01      1.094742e+01     7.044005e+00       1.094731e+01   \n",
       "min   -3.000000e+02     -3.440696e+03    -3.488080e+03      -3.440696e+03   \n",
       "25%    6.000000e+00     -7.399201e+01     4.073514e+01      -7.399136e+01   \n",
       "50%    8.500000e+00     -7.398174e+01     4.075281e+01      -7.398010e+01   \n",
       "75%    1.250000e+01     -7.396703e+01     4.076725e+01      -7.396365e+01   \n",
       "max    9.396336e+04      3.456223e+03     3.378013e+03       3.456223e+03   \n",
       "\n",
       "       dropoff_latitude  passenger_count  abs_diff_longitude  \\\n",
       "count      5.529894e+07     5.529894e+07        5.529894e+07   \n",
       "mean       3.995314e+01     1.685440e+00        2.251316e-02   \n",
       "std        7.044055e+00     1.326790e+00        3.854502e-02   \n",
       "min       -3.488080e+03     0.000000e+00        0.000000e+00   \n",
       "25%        4.073421e+01     1.000000e+00        5.827000e-03   \n",
       "50%        4.075332e+01     1.000000e+00        1.244900e-02   \n",
       "75%        4.076821e+01     2.000000e+00        2.370300e-02   \n",
       "max        3.378013e+03     2.080000e+02        4.989833e+00   \n",
       "\n",
       "       abs_diff_latitude  \n",
       "count       5.529894e+07  \n",
       "mean        2.110157e-02  \n",
       "std         2.903143e-02  \n",
       "min         0.000000e+00  \n",
       "25%         6.606000e-03  \n",
       "50%         1.387000e-02  \n",
       "75%         2.697000e-02  \n",
       "max         4.991325e+00  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7ec27e",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Find some values (at least two) that still looks odd to you in the table above.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4bebbd-a2f0-45bc-98dc-dbbb78f204cb",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "The minimum fare is negative, and the maximum fare is 93,963$, which is unlikely. Also, the min_passenger count is 0, which is also unlikely for a taxi. After doing some research, normal longitudes in New-York should be situated between -74.3 and -73.7, and normal latitudes between 40.5 and 40.9. Let's clean all of this. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c16be8e-ad41-4a77-b047-29abfb6458f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the Haversine distance between two points given their longitude and latitude.\n",
    "    \"\"\"\n",
    "    # Earth radius in kilometers\n",
    "    R = 6371.0\n",
    "    \n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lon1_rad = np.radians(lon1)\n",
    "    lat1_rad = np.radians(lat1)\n",
    "    lon2_rad = np.radians(lon2)\n",
    "    lat2_rad = np.radians(lat2)\n",
    "    \n",
    "    # Calculate differences in longitude and latitude\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    \n",
    "    # Calculate Haversine formula\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5a909f6-b96d-467a-afb3-36e2c46cc893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        fare_amount      pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
      "count  5.406130e+07             54061296      5.406130e+07     5.406130e+07   \n",
      "min   -1.167535e+00  2009-01-01 00:00:27     -3.383909e+01    -3.887521e+01   \n",
      "25%   -5.497328e-01  2010-08-17 21:00:15     -4.359663e-01    -4.481609e-01   \n",
      "50%   -2.918854e-01  2012-03-25 00:06:09     -1.756986e-01     8.092874e-02   \n",
      "75%    1.206704e-01  2013-10-23 16:07:03      1.778943e-01     5.256596e-01   \n",
      "max    9.970134e+01  2015-06-30 23:59:54      3.242341e+01     2.352404e+01   \n",
      "mean   2.621296e-17                 <NA>     -7.779391e-14    -2.807909e-14   \n",
      "std    1.000000e+00                 <NA>      1.000000e+00     1.000000e+00   \n",
      "\n",
      "       dropoff_longitude  dropoff_latitude  passenger_count   hour_of_day  \\\n",
      "count       5.406130e+07      5.406130e+07     5.406130e+07  5.406130e+07   \n",
      "min        -3.456088e+01     -3.572656e+01    -5.261134e-01 -2.073170e+00   \n",
      "25%        -4.490522e-01     -4.429558e-01    -5.261134e-01 -6.921124e-01   \n",
      "50%        -1.621297e-01      7.713077e-02    -5.261134e-01  7.514166e-02   \n",
      "75%         2.374181e-01      4.912066e-01     2.350704e-01  8.423957e-01   \n",
      "max         3.316510e+01      2.138257e+01     1.570389e+02  1.456199e+00   \n",
      "mean       -2.030031e-13     -1.288561e-13     1.851362e-18 -7.816571e-17   \n",
      "std         1.000000e+00      1.000000e+00     1.000000e+00  1.000000e+00   \n",
      "\n",
      "        day_of_week         month  abs_diff_longitude  abs_diff_latitude  \\\n",
      "count  5.406130e+07  5.406130e+07        5.406130e+07       5.406130e+07   \n",
      "min    0.000000e+00 -1.533333e+00        0.000000e+00       0.000000e+00   \n",
      "25%    1.000000e+00 -9.513289e-01        6.168000e-03       6.962000e-03   \n",
      "50%    3.000000e+00 -7.832334e-02        1.274000e-02       1.421000e-02   \n",
      "75%    5.000000e+00  7.946823e-01        2.403000e-02       2.734600e-02   \n",
      "max    6.000000e+00  1.667688e+00        1.539527e+00       1.547080e+00   \n",
      "mean   3.041093e+00  1.020528e-16        2.281184e-02       2.144605e-02   \n",
      "std    1.949116e+00  1.000000e+00        3.527562e-02       2.687701e-02   \n",
      "\n",
      "           distance  pickup_longitude_squared  pickup_latitude_squared  \\\n",
      "count  5.406130e+07              5.406130e+07             5.406130e+07   \n",
      "min   -8.368557e-01             -3.383909e+01            -3.887521e+01   \n",
      "25%   -5.220057e-01             -4.359663e-01            -4.481609e-01   \n",
      "50%   -2.960123e-01             -1.756986e-01             6.549461e-03   \n",
      "75%    1.464102e-01              3.164639e-02             2.763180e-01   \n",
      "max    4.290619e+01              1.051277e+03             5.533804e+02   \n",
      "mean   1.191622e-16              5.488670e-01             1.098032e-01   \n",
      "std    1.000000e+00              9.547147e+00             7.208517e+00   \n",
      "\n",
      "       dropoff_longitude_squared  dropoff_latitude_squared  distance_squared  \n",
      "count               5.406130e+07              5.406130e+07      5.406130e+07  \n",
      "min                -3.456088e+01             -3.572656e+01     -8.368557e-01  \n",
      "25%                -4.490522e-01             -4.429558e-01     -5.220057e-01  \n",
      "50%                -1.621297e-01              5.949156e-03     -2.960123e-01  \n",
      "75%                 5.636738e-02              2.412839e-01      2.143595e-02  \n",
      "max                 1.099924e+03              4.572145e+02      1.840941e+03  \n",
      "mean                4.767107e-01              1.163003e-01      5.507559e-01  \n",
      "std                 9.112750e+00              5.487889e+00      1.255466e+01  \n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask_ml.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "train_df = dd.read_csv('gs://obd-dask23/train.csv', storage_options={'token': 'anon'}).persist()\n",
    "\n",
    "#Drop NA values\n",
    "train_df = train_df.dropna(how='any')\n",
    "\n",
    "#load and convert Data time\n",
    "train_df['pickup_datetime'] = dd.to_datetime(train_df['pickup_datetime'], utc=True)\n",
    "# Extract hour and month\n",
    "train_df['hour_of_day'] = train_df['pickup_datetime'].dt.hour\n",
    "train_df['day_of_week'] = train_df['pickup_datetime'].dt.dayofweek  # 0 for monday, 6 for sunday\n",
    "train_df['month'] = train_df['pickup_datetime'].dt.month\n",
    "\n",
    "# Définition de la fonction add_travel_vector_features\n",
    "def add_travel_vector_features(df):\n",
    "    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n",
    "    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n",
    "\n",
    "add_travel_vector_features(train_df)\n",
    "\n",
    "train_df = train_df[(train_df.abs_diff_longitude < 5) & (train_df.abs_diff_latitude < 5)]\n",
    "\n",
    "# Supprimer les valeurs aberrantes pour le tarif et le nombre de passagers\n",
    "train_df = train_df[(train_df['fare_amount'] > 0) & (train_df['fare_amount'] <= 1000)]\n",
    "train_df = train_df[train_df['passenger_count'] > 0]\n",
    "\n",
    "# Extract hour of the day and month from pickup datetime\n",
    "train_df['pickup_datetime'] = dd.to_datetime(train_df['pickup_datetime'])\n",
    "train_df['hour_of_day'] = train_df['pickup_datetime'].dt.hour\n",
    "train_df['month'] = train_df['pickup_datetime'].dt.month\n",
    "\n",
    "# Restrain values of lat/long to NYC (googled it)\n",
    "train_df = train_df[(train_df['pickup_longitude'] >= -75.3) & (train_df['pickup_longitude'] <= -72.7)]\n",
    "train_df = train_df[(train_df['pickup_latitude'] >= 39.5) & (train_df['pickup_latitude'] <= 41.5)]\n",
    "train_df = train_df[(train_df['dropoff_longitude'] >= -75.3) & (train_df['dropoff_longitude'] <= -72.7)]\n",
    "train_df = train_df[(train_df['dropoff_latitude'] >= 39.5) & (train_df['dropoff_latitude'] <= 41.5)]\n",
    "\n",
    "# Calculate distances with haversine function\n",
    "train_df['distance'] = haversine_distance(train_df['pickup_longitude'], train_df['pickup_latitude'], train_df['dropoff_longitude'], train_df['dropoff_latitude'])\n",
    "\n",
    "# Normalize numerical features\n",
    "numerical_features = ['fare_amount', 'passenger_count', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'distance', 'hour_of_day', 'month']\n",
    "scaler = StandardScaler()\n",
    "train_df[numerical_features] = scaler.fit_transform(train_df[numerical_features])\n",
    "\n",
    "# Add non linear features\n",
    "positive_numerical_features = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'distance']\n",
    "\n",
    "def square_positive(x):\n",
    "    return np.where(x > 0, x ** 2, x)\n",
    "\n",
    "for feature in positive_numerical_features:\n",
    "    train_df[f'{feature}_squared'] = train_df[feature].map_partitions(square_positive)\n",
    "\n",
    "# Print statistics\n",
    "print(train_df.describe().compute())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84739b99",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Do you think we could parallelize things better for any of our computation or data access? (It's a trap).\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0968301b-aed0-4402-8b65-90af6565c5bd",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "Over-parallelization can introduce unnecessary overhead and complexity without proportional benefits. The goal should be to find a balance that leverages parallelism effectively while minimizing overhead and efficiently utilizing available resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead4e91",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "### BONUS Questions (you don't have to do this, just go back to it if you want to improve, skip it at first)\n",
    "\n",
    "Some other questions to practice\n",
    "\n",
    "- Can you see a correlation between the fare amount and the dropoff latitude? Answer by doing a dask dataframe computation.\n",
    "\n",
    "First you'll need to round the dropoff latitude to have some sort of categories using Series.round() function.\n",
    "\n",
    "Then, just group_by this new colon to have some answer (and don't forget to compute to get the results).\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "78f631f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rounded_dropoff_latitude\n",
       "40.0    17.286603\n",
       "41.0    11.328747\n",
       "42.0     9.520000\n",
       "Name: fare_amount, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "train_df['rounded_dropoff_latitude'] = train_df['dropoff_latitude'].round()\n",
    "\n",
    "result = train_df.groupby('rounded_dropoff_latitude')['fare_amount'].mean()\n",
    "\n",
    "computed_result = result.compute()\n",
    "\n",
    "computed_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f28182",
   "metadata": {},
   "source": [
    "OK, this don't give a lot of insights, but it looks like we've got some strange values somewhere!\n",
    "\n",
    "<br>\n",
    "\n",
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "- Let's just have a look of non extreme values, so probably some records at the middle of the results.\n",
    "We need first to sort the resulting series by index before looking at the middle of it.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b1430445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rounded_dropoff_latitude\n",
      "23.0    10.000000\n",
      "24.0     8.766667\n",
      "25.0     5.800000\n",
      "26.0    18.325000\n",
      "27.0     6.333333\n",
      "28.0     9.500000\n",
      "29.0     8.320000\n",
      "30.0    11.035294\n",
      "31.0     8.190000\n",
      "32.0     9.055556\n",
      "Name: fare_amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Sort the resulting series by index\n",
    "sorted_result = computed_result.sort_index()\n",
    "\n",
    "# Let's look at the middle values of the sorted series\n",
    "middle_index = len(sorted_result) // 2\n",
    "middle_values = sorted_result.iloc[middle_index - 5: middle_index + 5]\n",
    "\n",
    "print(middle_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c8b2eca-a4c1-4c44-8a40-d2ad5cfe0cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53971981"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd946db2",
   "metadata": {},
   "source": [
    "OK, this is not really useful, but it's an exercise!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b40adc",
   "metadata": {},
   "source": [
    "## Training a model in a distributed way\n",
    "\n",
    "Let's begin with a linear model that we can distributed with Dask ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2e693a",
   "metadata": {},
   "source": [
    "### Building our feature vectors\n",
    "\n",
    "Here again define a method so that we can use it later for our test set evaluation.\n",
    "\n",
    "<br>\n",
    "\n",
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Just do the same as with the Pandas example by defining a get_input_matrix(df) function. But this time you'll generate a dask array (not numpy) using `to_dask_array(lengths=True)` method on the dataframe object instead of `np.column_stack` (look a bit a dask docs in order to find how to use this method). You should do a method that generate the X input features dask array, and also the same with y training results. You can do just one method that return both (return X, y). \n",
    "- It is a good idea to persist() arrays in memory in or after the call.\n",
    "- This time, we'll add the feature 'passenger_count' in addition to the distance vectors, one more feature! So X must have 3 columns.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6d6b00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 11.4 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "\n",
    "def get_input_matrix(df):\n",
    "    features_df = df[['abs_diff_longitude', 'abs_diff_latitude', 'passenger_count']]\n",
    "    X = features_df.to_dask_array(lengths=True)\n",
    "    y = df['fare_amount'].to_dask_array(lengths=True)\n",
    "    X = X.persist()\n",
    "    y = y.persist()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aad88f",
   "metadata": {},
   "source": [
    "Then we get the values, and display train_X to have some insights of its size and chunking scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61c4eea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 12.6 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1468' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1527' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1472' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1486' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1485' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1512' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1525' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1514' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1521' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1483' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1506' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1510' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1494' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1467' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1497' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1471' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1500' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1518' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1504' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1517' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1462' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1519' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1456' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1536' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1452' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1470' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1523' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1478' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1533' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1534' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1453' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1457' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1528' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1511' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1476' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1464' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1520' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1530' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1455' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1459' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1487' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1451' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1535' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m train_X, train_y \u001b[38;5;241m=\u001b[39m \u001b[43mget_input_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m train_X\n",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m, in \u001b[0;36mget_input_matrix\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_input_matrix\u001b[39m(df):\n\u001b[1;32m      6\u001b[0m     features_df \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabs_diff_longitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabs_diff_latitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassenger_count\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m----> 7\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mfeatures_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dask_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfare_amount\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_dask_array(lengths\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mpersist()\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/dask/dataframe/core.py:1980\u001b[0m, in \u001b[0;36m_Frame.to_dask_array\u001b[0;34m(self, lengths, meta)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert a dask DataFrame to a dask array.\u001b[39;00m\n\u001b[1;32m   1958\u001b[0m \n\u001b[1;32m   1959\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1977\u001b[0m \u001b[38;5;124;03m-------\u001b[39;00m\n\u001b[1;32m   1978\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lengths \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1980\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_partitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1982\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m   1984\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_chunks(arr, lengths)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/dask/base.py:342\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    319\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/dask/base.py:628\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 628\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/threading.py:331\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%time\n",
    "train_X, train_y = get_input_matrix(train_df)\n",
    "train_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16204e42",
   "metadata": {},
   "source": [
    "### Distributed training a Linear model\n",
    "\n",
    "Be careful, this can take time, try first with few iterations (Use max_iter = 5 as a kwarg to LinearRegression constructor).\n",
    "\n",
    "see https://ml.dask.org/glm.html  \n",
    "and https://ml.dask.org/modules/generated/dask_ml.linear_model.LinearRegression.html#dask_ml.linear_model.LinearRegression\n",
    "\n",
    "<br>\n",
    "\n",
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Train a LinearRegression model from dask_ml.linear_model on our inputs\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ba9d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Answer needed here\n",
    "%time\n",
    "from dask_ml.linear_model import LinearRegression\n",
    "model = LinearRegression(max_iter=5)\n",
    "model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65ec13f",
   "metadata": {},
   "source": [
    "## Evaluating our model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b3b96f",
   "metadata": {},
   "source": [
    "#### First we should load the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e78929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = dd.read_csv('gs://obd-dask23/test_cleaned.csv', storage_options={'token': 'anon'}).persist()\n",
    "\n",
    "# Delete na values\n",
    "test_df = test_df.dropna(how='any')\n",
    "\n",
    "# convert to datetime format\n",
    "test_df['pickup_datetime'] = dd.to_datetime(test_df['pickup_datetime'], utc=True)\n",
    "\n",
    "# Extract day, hour, month\n",
    "test_df['hour_of_day'] = test_df['pickup_datetime'].dt.hour\n",
    "train_df['day_of_week'] = train_df['pickup_datetime'].dt.dayofweek  # 0 for monday, 6 for sunday\n",
    "test_df['month'] = test_df['pickup_datetime'].dt.month\n",
    "\n",
    "# Add travel vectors\n",
    "add_travel_vector_features(test_df)\n",
    "\n",
    "# Calculate Haversine distance\n",
    "test_df['distance'] = haversine_distance(test_df['pickup_longitude'], test_df['pickup_latitude'], test_df['dropoff_longitude'], test_df['dropoff_latitude'])\n",
    "\n",
    "# Normalize\n",
    "test_df[numerical_features] = scaler.transform(test_df[numerical_features])\n",
    "\n",
    "# Nonlinear features\n",
    "for feature in positive_numerical_features:\n",
    "    test_df[f'{feature}_squared'] = test_df[feature].map_partitions(square_positive)\n",
    "\n",
    "print(test_df.describe().compute())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0695ac",
   "metadata": {},
   "source": [
    "Adding our features to the test set and getting our feature array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2432c8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 229.05 kiB </td>\n",
       "                        <td> 229.05 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (9773, 3) </td>\n",
       "                        <td> (9773, 3) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 1 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float64 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"75\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 25.412616514582485,0.0 25.412616514582485,120.0 0.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.706308\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >3</text>\n",
       "  <text x=\"45.412617\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,45.412617,60.000000)\">9773</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<values, shape=(9773, 3), dtype=float64, chunksize=(9773, 3), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_travel_vector_features(test_df)\n",
    "test_X, test_y = get_input_matrix(test_df)\n",
    "test_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245a45fa",
   "metadata": {},
   "source": [
    "We can use the score method inherited from Scikit learn, it gives some hints on the model performance (but our scoring board will be on RMSE). Even if for linear models, score if often low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0bc8e4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6438779855103591"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "65be4dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31.94932154, 10.4277079 , 13.41553028, ...,  8.44994263,\n",
       "       10.06444395,  7.22275752])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_X).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56e0b52",
   "metadata": {},
   "source": [
    "#### Compute the RMSE\n",
    "\n",
    "https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/overview/evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9c12a254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5835034667820065"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(test_y.compute(), model.predict(test_X).compute(), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618691b3",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- What RMSE did you get? Compare it to the Pandas only computation.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f170c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We get a 6.41 RMSE, this is not bad at all considering 5 iterations only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c75934",
   "metadata": {},
   "source": [
    "# Distributed XGboost (optionnal, you can skip it at first)\n",
    "\n",
    "Just use the documentation here https://xgboost.readthedocs.io/en/stable/tutorials/dask.html#overview to train a model on this dataset using xgboost.\n",
    "\n",
    "<br>\n",
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Just copy/paste the example (dtrain = ..., output = ...), and modify some input variables.\n",
    "- Then make a prediction (but don't forget to use your test set, not as in the prediction = ... example from the Xgboost doc).\n",
    "- Compute the mean square error on it.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c158497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.dask.DaskDMatrix(client, train_X, train_y)\n",
    "output = xgb.dask.train(\n",
    "    client,\n",
    "    {\"verbosity\": 2, \"tree_method\": \"hist\", \"objective\": \"reg:squarederror\"},\n",
    "    dtrain,\n",
    "    num_boost_round=4,\n",
    "    evals=[(dtrain, \"train\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c42822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.dask.DaskDMatrix(client, test_X, test_y)\n",
    "prediction = xgb.dask.predict(client, output, dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b580369c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.062154804026349"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(test_y.compute(), prediction.compute(), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993d1443",
   "metadata": {},
   "source": [
    "## Use Dask to scale computation on Hyper Parameter Search\n",
    "\n",
    "As seen above, Dask is well suited to distribute Data and learn a model on a big Data set. However, not all the models can be trained in parallel on sub chunks of Data. See https://scikit-learn.org/stable/computing/scaling_strategies.html for the compatible models of Scikit learn for example.\n",
    "\n",
    "Dask can also be used to train several models in parallel on small datasets, this is what we'll try now.\n",
    "\n",
    "We will just take a sample of the training set, and try to learn several models with different hyper parameters, and find the best one.\n",
    "\n",
    "Dask Hyper parameter search : https://ml.dask.org/hyper-parameter-search.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc0e7a",
   "metadata": {},
   "source": [
    "First we'll take a small subset of the Data, 5% is a maximum if we want to avoir memory issues on our workers and have appropriate training times. You can try with less if the results are still good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f5c06652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a sample of the input data, get it as pandas dataframe\n",
    "train_sample_df = train_df.sample(frac=0.05, random_state=270120)\n",
    "# Get feature vectors out of it\n",
    "train_sample_X, train_sample_y = get_input_matrix(train_sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c03fe60",
   "metadata": {},
   "source": [
    "In order to optimize things, we can also change the type of the features to more appropriate and small types.\n",
    "\n",
    "We also need to use Numpy arrays, so we'll gather the result from Dask to local variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fdee85b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.031015  , 0.02671   , 1.        ],\n",
       "       [0.00778   , 0.01741   , 2.        ],\n",
       "       [0.0091    , 0.010142  , 1.        ],\n",
       "       ...,\n",
       "       [0.19846   , 0.092866  , 1.        ],\n",
       "       [0.028012  , 0.032991  , 1.        ],\n",
       "       [0.00333405, 0.00214005, 1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_sample_X = train_sample_X.astype('float32').compute()\n",
    "train_sample_y = train_sample_y.astype('float32').compute()\n",
    "train_sample_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6971e4a",
   "metadata": {},
   "source": [
    "What size is our dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d9bf7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33179432"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(train_sample_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f2ee9",
   "metadata": {},
   "source": [
    "About 32MB, this is still quite a big dataset for standard machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1a4fc2",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "- Now, just use hyper parameter search Dask API to distribute the search. You can either use joblib integration with Sklearn or dask_ml directly. \n",
    "\n",
    "**Be careful: do not use model too long to train, and limit their complexity at first or the combinations of hyper parameters you'll use. Hint, start first with a simple LinearModel like SGDRegressor and not more than 10 iterations per model.**\n",
    "</span>\n",
    "\n",
    "So start with something like:\n",
    "\n",
    "- RandomizedSearchCV https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html, with cv=2, n_iter=50, verbose=10\n",
    "- With sklearn.linear_model.SGDRegressor with max_iter=20\n",
    "- Use this parameter space:\n",
    "```python\n",
    "from scipy.stats import uniform, loguniform\n",
    "param_space = {\n",
    "    \"average\": [True, False],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    \"alpha\": loguniform(1e-5, 1e-1),\n",
    "    \"learning_rate\": [\"invscaling\", \"adaptive\"],\n",
    "    \"power_t\": uniform(0, 1),\n",
    "}\n",
    "```\n",
    "- If you chose sklearn API, you want to import joblib, and use `with joblib.parallel_backend('dask'):` before fitting your model.\n",
    "- If you chose dask_ml API, https://ml.dask.org/hyper-parameter-search.html#basic-use, you'll don't need the with syntax, but just the correct imports: from dask_ml.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d3732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Answer needed here (with sklearn API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc43a312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 42.20 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 42.19 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 6.410277188110155e-05, 'average': False, 'learning_rate': 'invscaling', 'penalty': 'l2', 'power_t': 0.3143559810763267}\n",
      "Best score: 0.503800491630873\n",
      "CPU times: user 570 ms, sys: 216 ms, total: 785 ms\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from dask_ml.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from scipy.stats import uniform, loguniform\n",
    "\n",
    "# Define the parameter space\n",
    "param_space = {\n",
    "    \"average\": [True, False],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    \"alpha\": loguniform(1e-5, 1e-1),\n",
    "    \"learning_rate\": [\"invscaling\", \"adaptive\"],\n",
    "    \"power_t\": uniform(0, 1),\n",
    "}\n",
    "\n",
    "# Initialize the SGDRegressor\n",
    "model = SGDRegressor(max_iter=20)\n",
    "\n",
    "# Set up the randomized search with cross-validation\n",
    "search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_space,\n",
    "    n_iter=50,\n",
    "    cv=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Perform the search on the sampled data\n",
    "# Assuming train_sample_X and train_sample_y are already computed and converted to pandas DataFrame/series\n",
    "search.fit(train_sample_X, train_sample_y)\n",
    "\n",
    "# Results\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "print(\"Best score:\", search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5dcf013b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5477293631050179"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0cf1ae20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.396363262943413"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(test_y, search.predict(test_X), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8545454",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "- So how does this result compare to the previous one we got with a distributed leaning with a linear model on all the dataset?\n",
    "    \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db09016-2251-4ffa-a8f4-df5ed3f9d31b",
   "metadata": {},
   "source": [
    "**ANSWER** \n",
    "\n",
    "Our RMSE is slightly better, like the accuracy, but the difference is not very shocking. Maybe we should run a more ambitious GridSearch and increase the number of iterations to see a real difference. XGBoost, however, was much more efficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661cfe73",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "- Try with https://ml.dask.org/modules/generated/dask_ml.model_selection.HyperbandSearchCV.html#dask_ml.model_selection.HyperbandSearchCV instead of RandomizedSearchCV.\n",
    "    \n",
    "You'd prefer to use dask_ml.model_selection.HyperbandSearchCV (instead of joblib). And just need to change n_iter to max_iter, and remove another arg.\n",
    "    \n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f223ae96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 42.19 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'power_t': 0.1, 'penalty': 'l1', 'learning_rate': 'adaptive', 'average': True, 'alpha': 1e-05}\n",
      "Best score: 0.5114013035648637\n",
      "CPU times: user 881 ms, sys: 577 ms, total: 1.46 s\n",
      "Wall time: 51.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from dask_ml.model_selection import HyperbandSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "model = SGDRegressor(max_iter=20)\n",
    "#Unfortunately, uniform distribution are not supported here\n",
    "param_space = {\n",
    "    'average': [True, False],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'alpha': [1e-5, 1e-3, 1e-1],  \n",
    "    'learning_rate': ['invscaling', 'adaptive'],\n",
    "    'power_t': [0.1, 0.3, 0.5] }\n",
    "\n",
    "search = HyperbandSearchCV(\n",
    "    model,\n",
    "    param_space,\n",
    "    max_iter=50,\n",
    "    patience=True,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "search.fit(train_sample_X, train_sample_y)\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "print(\"Best score:\", search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b489ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5430723048471259"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f90d9c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.429210792045596"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(test_y, search.predict(test_X), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9592bec",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- OK, Linear models are what they are, we'll try to do better with Random forest! https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "    \n",
    "Return to RandomizedSearchCV for now.\n",
    "\n",
    "Caution: use limited trees, small number of estimators < 10 and max_depth < 40 at first\n",
    "</span>\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "param_space = {\n",
    "'n_estimators': range(4,10),\n",
    "'max_depth': range(10,40),\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fcc66ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 42.19 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 42.19 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 7, 'max_depth': 11}\n",
      "Best score: 0.7440967136079293\n"
     ]
    }
   ],
   "source": [
    "from dask_ml.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import dask.array as da\n",
    "\n",
    "# Define the parameter space\n",
    "param_space = {\n",
    "    'n_estimators': range(4, 10),  # Fewer estimators for quicker iterations\n",
    "    'max_depth': range(10, 40),    # Limited depth to prevent overly complex models initially\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Setup Randomized Search with cross-validation\n",
    "search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_space,\n",
    "    n_iter=50,  \n",
    "    cv=2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "search.fit(train_sample_X, train_sample_y)\n",
    "\n",
    "# Print the results\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "print(\"Best score:\", search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cd8318",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- If you did not used joblib, try it now.\n",
    "\n",
    "What do you observe when training RandomForest tree on Dask parallelization Dashboard with joblib? Can you explain why there are so many tasks?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6dee3a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n",
      "Best parameters: {'n_estimators': 7, 'max_depth': 11}\n",
      "Best score: 0.7446222701628291\n",
      "CPU times: user 1.48 s, sys: 448 ms, total: 1.92 s\n",
      "Wall time: 12min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from dask.distributed import Client\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from joblib import parallel_backend\n",
    "\n",
    "# Define the parameter space\n",
    "param_space = {\n",
    "    'n_estimators': range(4, 10), \n",
    "    'max_depth': range(10, 40),\n",
    "}\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_space,\n",
    "    n_iter=50,\n",
    "    cv=2,\n",
    "    random_state=42,\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "# Use Dask's Joblib backend to distribute the computation\n",
    "with parallel_backend('dask'):\n",
    "    search.fit(train_sample_X, train_sample_y)\n",
    "\n",
    "# Print the results\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "print(\"Best score:\", search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "19be8363-9571-4d5f-9b30-d92d51596c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=11, n_estimators=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=11, n_estimators=7)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=11, n_estimators=7)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#Take a sample of the input data, get it as pandas dataframe\n",
    "train_sample_df = train_df.sample(frac=0.05, random_state=270120)\n",
    "# Get feature vectors out of it\n",
    "train_sample_X, train_sample_y = get_input_matrix(train_sample_df)\n",
    "train_sample_X = train_sample_X.astype('float32').compute()\n",
    "train_sample_y = train_sample_y.astype('float32').compute()\n",
    "model = RandomForestRegressor(n_estimators=7, max_depth=11)\n",
    "model.fit(train_sample_X, train_sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "35a398ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7915528392051733"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e72798f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4464183336257591"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(test_y, model.predict(test_X), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fba8bc",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Did you get better results with RandomForest? Do you know why?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39708a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Much better score (74% accuracy with ml, and 77% with joblib) ! \n",
    "##I assume that the distribution of the data highly non-linear, since random forest use to perform well on non-linear data distribution\n",
    "#I reached an RMSE of 4.53, which is pretty close to 4.5 !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83862a8",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "# Extend this notebook\n",
    "    \n",
    "With the example aboves, I reached a score of about 4.5 RMSE. Try to do better!\n",
    "\n",
    "- Add new features to the input Data using Dask Dataframes, or clean it better. Reapply the learning above with these new features. Do you get better results? Some suggestions for a better leaning:\n",
    "  - Try to clean extremes or non realistic values you identified above in the training set.\n",
    "  - Apply some normalisation or regularization or other feature transformation? See https://ml.dask.org/preprocessing.html.\n",
    "  - Add some non linear features (square feature, for example square the travel vector)\n",
    "  - Maybe the hour of the day, or the month, has some impact on fares? Try to add features. See https://matthewrocklin.com/blog/work/2017/01/12/dask-dataframes for some hints on how to do this.\n",
    "  - Maybe try to find a way to use the start and drop off locations?\n",
    "- Improve the model parameters or find a better one. Try using this time dask_ml HyperbandSearchCV. See https://ml.dask.org/hyper-parameter-search.html#basic-use. You can use it for example with https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor.\n",
    "- Try one single RandomForestRegressor (with no HyperParameterSearch), but with big depth and estimators. This single model fitting should be distributed on dask with joblib (Random Forest is about training several decision trees).\n",
    "\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4fe4a8-fc3b-4704-8823-4788c4bafb8b",
   "metadata": {},
   "source": [
    "- Apply some normalisation or regularization or other feature transformation? See https://ml.dask.org/preprocessing.html.\n",
    "  - Add some non linear features (square feature, for example square the travel vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feb00e5-7b3f-4f0d-9b0b-af7278933b19",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
