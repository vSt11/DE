{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5080c7e1",
   "metadata": {},
   "source": [
    "# Welcome to the DE SDD Evaluation!\n",
    "\n",
    "Today, the goal is to understand how a distributed system can be useful when dealing with medium to large scale data sets.  \n",
    "We'll see that Dask start to be nice as soon as the Data we need to process doesn't quite fit in memory, but also if we\n",
    "need to launch several computations in parallel.\n",
    "\n",
    "In this evaluation, you will:\n",
    "- Use Dask to read and understand the several gigabytes input dataset in a interactive way,\n",
    "- Preprocess the data in a distributed way: cleaning it up and adding some useful features,\n",
    "- Launch some model training that can be parallelized on a big dataset,\n",
    "- Reduce the dataset and train more accurate models on less Data,\n",
    "- Do an hyper parameter search to find the best model on a small sample of Data.\n",
    "\n",
    "In order to run and fill this notebook, you'll need to first deploy a Dask enabled Kubernetes cluster as seen before. So please use the Kubernetes_DaskHub notebook for the steps to do it.\n",
    "\n",
    "Once the Jupyterhub is up, you can clone the DE repository from a Jupyterlab terminal to get this notebook, and select the default kernel.\n",
    "```\n",
    "git clone https://github.com/SupaeroDataScience/DE.git\n",
    "cd DE/notebooks\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9f615b",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "It is some statistics about NY Taxi cabs. \n",
    "\n",
    "See https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/overview, or https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data.\n",
    "        \n",
    "The goal of this evaluation will be to generate a model using machine learning algorithms that will predict the fare amount\n",
    "of a taxi ride given the other input parameters we have.\n",
    "\n",
    "The model will be evaluated using the Root mean squared error algorithm:  \n",
    "https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/overview/evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255611eb",
   "metadata": {},
   "source": [
    "## Try to analyze the Data using Kaggles' start-up code\n",
    "\n",
    "As an introduction, we'll use Kaggle starters' code to get some insights on the data set and\n",
    "computations we'll do and measure pandas library (non parallelized access and process) performance.\n",
    "\n",
    "See https://www.kaggle.com/dster/nyc-taxi-fare-starter-kernel-simple-linear-model where this comes from.\n",
    "\n",
    "This Kaggle method will set the bar to beat with our own tools. I'm sure you can do it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61175e73",
   "metadata": {},
   "source": [
    "#### Reading the data with pandas\n",
    "\n",
    "We're reading only about 20% from the whole data set. Using the storage_options kwarg was mandatory for me to avoid auth issues, don't forget it when you read public data from cloud storage during this evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6a9896e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Please install gcsfs to access Google Storage",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fsspec/registry.py:235\u001b[0m, in \u001b[0;36mget_filesystem_class\u001b[0;34m(protocol)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 235\u001b[0m     register_implementation(protocol, \u001b[43m_import_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbit\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fsspec/registry.py:270\u001b[0m, in \u001b[0;36m_import_class\u001b[0;34m(cls, minv)\u001b[0m\n\u001b[1;32m    269\u001b[0m s3 \u001b[38;5;241m=\u001b[39m mod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3fs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 270\u001b[0m mod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s3 \u001b[38;5;129;01mand\u001b[39;00m mod\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m<\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gcsfs/__init__.py:5\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m get_versions\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GCSFileSystem\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmapping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GCSMap\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gcsfs/core.py:19\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masyn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AsyncFileSystem, sync, sync_wrapper\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NoOpCallback\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fsspec/asyn.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Iterable\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_CALLBACK\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FSTimeoutError\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DEFAULT_CALLBACK' from 'fsspec.callbacks' (/home/raphi/.local/lib/python3.10/site-packages/fsspec/callbacks.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:716\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    713\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 716\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    725\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:414\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 414\u001b[0m     file_obj \u001b[38;5;241m=\u001b[39m \u001b[43mfsspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfsspec_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mopen()\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# GH 34626 Reads from Public Buckets without Credentials needs anon=True\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(err_types_to_retry_with_anon):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fsspec/core.py:452\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(urlpath, mode, compression, encoding, errors, protocol, newline, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\n\u001b[1;32m    393\u001b[0m     urlpath,\n\u001b[1;32m    394\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    401\u001b[0m ):\n\u001b[1;32m    402\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Given a path or paths, return one ``OpenFile`` object.\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m      https://filesystem-spec.readthedocs.io/en/latest/api.html#other-known-implementations\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 452\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mopen_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43murlpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43murlpath\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out:\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(urlpath)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fsspec/core.py:280\u001b[0m, in \u001b[0;36mopen_files\u001b[0;34m(urlpath, mode, compression, encoding, errors, name_function, num, protocol, newline, auto_mkdir, expand, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_files\u001b[39m(\n\u001b[1;32m    202\u001b[0m     urlpath,\n\u001b[1;32m    203\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    214\u001b[0m ):\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Given a path or paths, return a list of ``OpenFile`` objects.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m    For writing, a str path must contain the \"*\" character, which will be filled\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m      https://filesystem-spec.readthedocs.io/en/latest/api.html#other-known-implementations\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m     fs, fs_token, paths \u001b[38;5;241m=\u001b[39m \u001b[43mget_fs_token_paths\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43murlpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mprotocol \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    290\u001b[0m         fs\u001b[38;5;241m.\u001b[39mauto_mkdir \u001b[38;5;241m=\u001b[39m auto_mkdir\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fsspec/core.py:610\u001b[0m, in \u001b[0;36mget_fs_token_paths\u001b[0;34m(urlpath, mode, num, name_function, storage_options, protocol, expand)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol:\n\u001b[1;32m    609\u001b[0m     storage_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprotocol\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m protocol\n\u001b[0;32m--> 610\u001b[0m chain \u001b[38;5;241m=\u001b[39m \u001b[43m_un_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43murlpath0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    611\u001b[0m inkwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# Reverse iterate the chain, creating a nested target_* structure\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fsspec/core.py:325\u001b[0m, in \u001b[0;36m_un_chain\u001b[0;34m(path, kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(bits):\n\u001b[1;32m    324\u001b[0m     protocol \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprotocol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m split_protocol(bit)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 325\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mget_filesystem_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     extra_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_kwargs_from_urls(bit)\n\u001b[1;32m    327\u001b[0m     kws \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(protocol, {})\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fsspec/registry.py:237\u001b[0m, in \u001b[0;36mget_filesystem_class\u001b[0;34m(protocol)\u001b[0m\n\u001b[1;32m    235\u001b[0m         register_implementation(protocol, _import_class(bit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 237\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(bit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merr\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m registry[protocol]\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprotocol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabstract\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mImportError\u001b[0m: Please install gcsfs to access Google Storage"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "train_df =  pd.read_csv('gs://obd-dask23/train.csv', nrows = 10, storage_options={'token': 'anon'})\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6641f721-badc-4517-ada0-9d90675bbe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gcsfs in /home/raphi/.local/lib/python3.10/site-packages (2024.2.0)\n",
      "Requirement already satisfied: fsspec==2024.2.0 in /home/raphi/.local/lib/python3.10/site-packages (from gcsfs) (2024.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in /home/raphi/.local/lib/python3.10/site-packages (from gcsfs) (1.0.0)\n",
      "Requirement already satisfied: decorator>4.1.2 in /home/raphi/.local/lib/python3.10/site-packages (from gcsfs) (4.4.2)\n",
      "Requirement already satisfied: google-cloud-storage in /home/raphi/.local/lib/python3.10/site-packages (from gcsfs) (2.14.0)\n",
      "Requirement already satisfied: requests in /home/raphi/.local/lib/python3.10/site-packages (from gcsfs) (2.31.0)\n",
      "Requirement already satisfied: google-auth>=1.2 in /home/raphi/.local/lib/python3.10/site-packages (from gcsfs) (2.23.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/raphi/.local/lib/python3.10/site-packages (from gcsfs) (3.8.6)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/raphi/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/raphi/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/raphi/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/raphi/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (3.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/raphi/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/raphi/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/raphi/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (23.1.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/raphi/.local/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs) (5.3.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/raphi/.local/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth>=1.2->gcsfs) (0.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/raphi/.local/lib/python3.10/site-packages (from google-auth-oauthlib->gcsfs) (1.3.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /home/raphi/.local/lib/python3.10/site-packages (from google-cloud-storage->gcsfs) (2.4.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /home/raphi/.local/lib/python3.10/site-packages (from google-cloud-storage->gcsfs) (1.5.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /home/raphi/.local/lib/python3.10/site-packages (from google-cloud-storage->gcsfs) (2.17.0)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /home/raphi/.local/lib/python3.10/site-packages (from google-cloud-storage->gcsfs) (2.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->gcsfs) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->gcsfs) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->gcsfs) (2020.6.20)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /home/raphi/.local/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs) (4.24.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /home/raphi/.local/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs) (1.62.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth>=1.2->gcsfs) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install gcsfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df98a8b",
   "metadata": {},
   "source": [
    "#### Analysing dataset, adding some features and droping null values\n",
    "\n",
    "Let's see if we can see some correlation between passengers count and fare amount?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f584bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 196 ms, sys: 1.05 ms, total: 198 ms\n",
      "Wall time: 195 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "passenger_count\n",
       "0       9.047261\n",
       "1      11.216596\n",
       "2      11.800345\n",
       "3      11.536788\n",
       "4      11.754418\n",
       "5      11.218924\n",
       "6      12.141258\n",
       "7      36.582500\n",
       "8      32.665000\n",
       "9      37.366667\n",
       "34     13.300000\n",
       "51      9.300000\n",
       "129     8.500000\n",
       "208    11.140000\n",
       "Name: fare_amount, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_df.groupby(train_df.passenger_count).fare_amount.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6623ecc",
   "metadata": {},
   "source": [
    "Maybe adding some features about the distance of the trip could be a good idea?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8b70ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 120 ms, sys: 2.96 ms, total: 123 ms\n",
      "Wall time: 120 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 'abs_diff_longitude' 'abs_diff_latitude' reprensenting the \"Manhattan vector\" from\n",
    "# the pickup location to the dropoff location.\n",
    "def add_travel_vector_features(df):\n",
    "    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n",
    "    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n",
    "\n",
    "add_travel_vector_features(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8c6ca0",
   "metadata": {},
   "source": [
    "Are there some undefined values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01248590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key                    0\n",
      "fare_amount            0\n",
      "pickup_datetime        0\n",
      "pickup_longitude       0\n",
      "pickup_latitude        0\n",
      "dropoff_longitude     74\n",
      "dropoff_latitude      74\n",
      "passenger_count        0\n",
      "abs_diff_longitude    74\n",
      "abs_diff_latitude     74\n",
      "dtype: int64\n",
      "CPU times: user 1.02 s, sys: 1.84 ms, total: 1.02 s\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ec78ab",
   "metadata": {},
   "source": [
    "We want to get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bcb7f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old size: 10000000\n",
      "New size: 9999926\n",
      "CPU times: user 1.76 s, sys: 286 ms, total: 2.04 s\n",
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Old size: %d' % len(train_df))\n",
    "train_df = train_df.dropna(how = 'any', axis = 'rows')\n",
    "print('New size: %d' % len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc2cd37",
   "metadata": {},
   "source": [
    "#### Quick analyze on new features and clean outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c501c429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 514 ms, sys: 68.6 ms, total: 583 ms\n",
      "Wall time: 742 ms\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGxCAYAAACXwjeMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0D0lEQVR4nO3de3hU1b3/8c9wyRBIMhAgtxJDgKggBpBYQrwAImhE6gX9UfF4oFYrilyKHimox1iVID3FSxEQbLkcSuE85SKtqMRCEitQkRIJF8MtQFoTIxAyJOCkhPX7w8MchiQwGZLM7OH9ep79PJm11+z9XUPtfJ61195jM8YYAQAAWFQzfxcAAABwOQgzAADA0ggzAADA0ggzAADA0ggzAADA0ggzAADA0ggzAADA0ggzAADA0lr4u4DGdvbsWX399dcKDw+XzWbzdzkAAMALxhidPHlScXFxatbs4nMvQR9mvv76a8XHx/u7DAAA4IOioiJ16tTpon2CPsyEh4dL+v7DiIiI8HM1AADAG06nU/Hx8e7v8YsJ+jBz7tJSREQEYQYAAIvxZokIC4ABAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClBf3PGQAAgMZx8NsKzd6wTwePVmpojxg9NaibX+ogzAAAgHo5capK//7eFu34+qS7La+oXDM/LtCKx1PVr2v7Jq2Hy0wAAKBeJvwhzyPInG/kgi1NXA1hBgAA1MPBbyuUu+/bi/aZs3F/E1XzPcIMAADw2uHjpy7Z59NLhJ2GRpgBAABeS4hsfck+tyR1bIJK/k/AhJnMzEzZbDZNmjTJ3WaMUUZGhuLi4hQaGqqBAwdq165d/isSAIArXJeOYbr1EmGlqe9qCogws3XrVs2fP1/Jycke7TNnztSsWbM0e/Zsbd26VTExMRoyZIhOnqx90REAAGh8v3moj5J/EFHrvhWPpzZxNQEQZioqKvTwww9rwYIFateunbvdGKM333xTzz//vO6//3717NlTixcv1qlTp7Rs2TI/VgwAwJXN0bql1o6/RRufHagHbviBesc79Nwd1+jQjGFNflu2FABhZty4cRo2bJhuv/12j/bCwkKVlJRo6NCh7ja73a4BAwZo06ZNdR7P5XLJ6XR6bAAAoOEldmij//p/vbVm3M1+e2Ce5OeH5i1fvlx///vftXXr1hr7SkpKJEnR0dEe7dHR0Tp8+HCdx8zMzNTLL7/csIUCAICA5beZmaKiIk2cOFFLly5Vq1at6uxns9k8XhtjarSdb+rUqSovL3dvRUVFDVYzAAAIPH6bmdm2bZtKS0vVt29fd1t1dbVyc3M1e/ZsFRQUSPp+hiY2Ntbdp7S0tMZszfnsdrvsdnvjFQ4AAAKK32ZmBg8erPz8fOXl5bm3lJQUPfzww8rLy1OXLl0UExOjrKws93uqqqqUk5OjtLQ0f5UNAAACjN9mZsLDw9WzZ0+PtjZt2qh9+/bu9kmTJmn69OlKSkpSUlKSpk+frtatW2vUqFH+KBkAAASggP7V7Oeee06nT5/WU089pbKyMvXr10/r169XeHi4v0sDAAABwmaMMf4uojE5nU45HA6Vl5crIqL2B/wAAIDAUp/vb78/ZwYAAOByEGYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAIClEWYAAICl+TXMzJ07V8nJyYqIiFBERIT69++vDz/80L1/zJgxstlsHltqaqofKwYAAIGmhT9P3qlTJ82YMUPdunWTJC1evFj33HOPtm/fruuuu06SdOedd2rhwoXu94SEhPilVgAAEJj8GmaGDx/u8fq1117T3LlztWXLFneYsdvtiomJ8Ud5AADAAgJmzUx1dbWWL1+uyspK9e/f392enZ2tqKgoXX311Xr88cdVWlp60eO4XC45nU6PDQAABC+/h5n8/HyFhYXJbrdr7NixWr16tXr06CFJSk9P1+9//3tt2LBBv/71r7V161bddtttcrlcdR4vMzNTDofDvcXHxzfVUAAAgB/YjDHGnwVUVVXpyJEjOnHihFauXKn33ntPOTk57kBzvuLiYiUkJGj58uW6//77az2ey+XyCDtOp1Px8fEqLy9XREREo40DAAA0HKfTKYfD4dX3t1/XzEjfL+g9twA4JSVFW7du1VtvvaV33323Rt/Y2FglJCRo3759dR7PbrfLbrc3Wr0AACCw+P0y04WMMXVeRjp27JiKiooUGxvbxFUBAIBA5deZmWnTpik9PV3x8fE6efKkli9fruzsbH300UeqqKhQRkaGRowYodjYWB06dEjTpk1Thw4ddN999/mzbAAAEED8Gma++eYbPfLIIyouLpbD4VBycrI++ugjDRkyRKdPn1Z+fr6WLFmiEydOKDY2VoMGDdKKFSsUHh7uz7IBAEAA8fsC4MZWnwVEAAAgMNTn+zvg1swAAADUB2EGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYml/DzNy5c5WcnKyIiAhFRESof//++vDDD937jTHKyMhQXFycQkNDNXDgQO3atcuPFQMAgEDj1zDTqVMnzZgxQ1988YW++OIL3XbbbbrnnnvcgWXmzJmaNWuWZs+era1btyomJkZDhgzRyZMn/Vk2AAAIIDZjjPF3EeeLjIzUr371Kz366KOKi4vTpEmTNGXKFEmSy+VSdHS0Xn/9dT3xxBNeHc/pdMrhcKi8vFwRERGNWToAAGgg9fn+Dpg1M9XV1Vq+fLkqKyvVv39/FRYWqqSkREOHDnX3sdvtGjBggDZt2uTHSgEAQCBp4e8C8vPz1b9/f3333XcKCwvT6tWr1aNHD3dgiY6O9ugfHR2tw4cP13k8l8sll8vlfu10OhuncAAAEBD8PjNzzTXXKC8vT1u2bNGTTz6p0aNHa/fu3e79NpvNo78xpkbb+TIzM+VwONxbfHx8o9UOAAD8z+9hJiQkRN26dVNKSooyMzPVq1cvvfXWW4qJiZEklZSUePQvLS2tMVtzvqlTp6q8vNy9FRUVNWr9AADAv/weZi5kjJHL5VJiYqJiYmKUlZXl3ldVVaWcnBylpaXV+X673e6+1fvcBgAAgpdf18xMmzZN6enpio+P18mTJ7V8+XJlZ2fro48+ks1m06RJkzR9+nQlJSUpKSlJ06dPV+vWrTVq1Ch/lg0AAAKIX8PMN998o0ceeUTFxcVyOBxKTk7WRx99pCFDhkiSnnvuOZ0+fVpPPfWUysrK1K9fP61fv17h4eH+LBsAAASQgHvOTEPjOTMAAFiPJZ8zAwAA4AvCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsDTCDAAAsLTLCjNVVVUqKCjQmTNnGqoeAACAevEpzJw6dUo//elP1bp1a1133XU6cuSIJGnChAmaMWNGgxYIAABwMT6FmalTp+rLL79Udna2WrVq5W6//fbbtWLFigYrDgAA4FJa+PKmNWvWaMWKFUpNTZXNZnO39+jRQwcOHGiw4gAAAC7Fp5mZb7/9VlFRUTXaKysrPcINAABAY/MpzNx444364IMP3K/PBZgFCxaof//+DVMZAACAF3y6zJSZmak777xTu3fv1pkzZ/TWW29p165d2rx5s3Jychq6RgAAgDr5NDOTlpamzz77TKdOnVLXrl21fv16RUdHa/Pmzerbt29D1wgAAFAnmzHG+LuIxuR0OuVwOFReXq6IiAh/lwMAALxQn+9vry8zOZ1OrwsgNAAAgKbidZhp27at13cqVVdX+1wQAABAfXgdZjZu3Oj++9ChQ/rFL36hMWPGuO9e2rx5sxYvXqzMzMyGrxIAAKAOPq2ZGTx4sB577DE99NBDHu3Lli3T/PnzlZ2d3VD1XTbWzAAAYD31+f726W6mzZs3KyUlpUZ7SkqKPv/8c6+Pk5mZqRtvvFHh4eGKiorSvffeq4KCAo8+Y8aMkc1m89hSU1N9KRsAAAQhn8JMfHy85s2bV6P93XffVXx8vNfHycnJ0bhx47RlyxZlZWXpzJkzGjp0qCorKz363XnnnSouLnZv69at86VsAAAQhHx6aN4bb7yhESNG6OOPP3bPkmzZskUHDhzQypUrvT7ORx995PF64cKFioqK0rZt23Trrbe62+12u2JiYnwpFQAABDmfZmbuuusu7d27Vz/60Y90/PhxHTt2TPfcc4/27t2ru+66y+diysvLJUmRkZEe7dnZ2YqKitLVV1+txx9/XKWlpT6fAwAABJeAeWieMUb33HOPysrK9Omnn7rbV6xYobCwMCUkJKiwsFAvvviizpw5o23btslut9c4jsvlksvlcr92Op2Kj49nATAAABbSKA/NO19ubu5F959/ichbTz/9tHbs2KG//vWvHu0jR450/92zZ0+lpKQoISFBH3zwge6///4ax8nMzNTLL79c7/MDAABr8mlmplmzmlenzn+gXn0fmjd+/HitWbNGubm5SkxMvGT/pKQkPfbYY5oyZUqNfczMAABgfY0+M1NWVubx+l//+pe2b9+uF198Ua+99prXxzHGaPz48Vq9erWys7O9CjLHjh1TUVGRYmNja91vt9trvfwEAACCk09hxuFw1GgbMmSI7Ha7fv7zn2vbtm1eHWfcuHFatmyZ3n//fYWHh6ukpMR9/NDQUFVUVCgjI0MjRoxQbGysDh06pGnTpqlDhw667777fCkdAAAEGZ/CTF06duxY46F3FzN37lxJ0sCBAz3aFy5cqDFjxqh58+bKz8/XkiVLdOLECcXGxmrQoEFasWKFwsPDG7J0AABgUT6FmR07dni8NsaouLhYM2bMUK9evbw+zqWW64SGhurjjz/2pUQAAHCF8CnM9O7dWzabrUYYSU1N1e9+97sGKQwAAMAbPoWZwsJCj9fNmjVTx44d1apVqwYpCgAAwFs+PQE4JydHMTExSkhIUEJCguLj49WqVStVVVVpyZIlDV0jAABAnXx6zkzz5s1VXFysqKgoj/Zjx44pKiqq3s+ZaUz1uU8dAAAEhvp8f/s0M2OM8XhI3jn/+Mc/ar1tGwAAoLHUa81Mnz59ZLPZZLPZNHjwYLVo8X9vr66uVmFhoe68884GLxIAAKAu9Qoz9957ryQpLy9Pd9xxh8LCwtz7QkJC1LlzZ40YMaJBCwQAALiYeoWZl156SZLUuXNnjRw5kruXAACA3/l0a/bo0aMbug4AAACfeB1mIiMjtXfvXnXo0EHt2rWrdQHwOcePH2+Q4gAAAC7F6zDzxhtvuH8P6Y033rhomAEAAGgqPj1nxkp4zgwAANbT6M+Zad68uUpLS2u0Hzt2TM2bN/flkAAAAD7x+aF5tXG5XAoJCbmsggAAAOqjXnczvf3225Ikm82m9957z+M5M9XV1crNzdW1117bsBUCAABcRL3CzBtvvCHp+5mZefPmeVxSOvfQvHnz5jVshQAAABdRrzBTWFgoSRo0aJBWrVqldu3aNUpRAAAA3vLpoXkbN25s6DoAAAB84lOYkb7/hey1a9fqyJEjqqqq8tg3a9asyy4MAADAGz6Fmb/85S/60Y9+pMTERBUUFKhnz546dOiQjDG64YYbGrpGAACAOvl0a/bUqVP1zDPPaOfOnWrVqpVWrlypoqIiDRgwQA8++GBD1wgAAFAnn8LMnj173D822aJFC50+fVphYWH65S9/qddff71BCwQAALgYn8JMmzZt5HK5JElxcXE6cOCAe9/Ro0cbpjIAAAAv+LRmJjU1VZ999pl69OihYcOG6ZlnnlF+fr5WrVql1NTUhq4RAACgTj6FmVmzZqmiokKSlJGRoYqKCq1YsULdunVzP1gPAACgKfCr2QAAIOA0+q9mAwAABAqvLzO1a9dONpvNq77Hjx/3uSAAAID68DrMvPnmm41YBgAAgG+8DjPnnitTHzNmzNDYsWPVtm3ber8XAADAG426Zmb69OlccgIAAI2qUcPMpW6UyszM1I033qjw8HBFRUXp3nvvVUFBQY1jZGRkKC4uTqGhoRo4cKB27drVmGUDAAAL8evdTDk5ORo3bpy2bNmirKwsnTlzRkOHDlVlZaW7z8yZMzVr1izNnj1bW7duVUxMjIYMGaKTJ0/6sXIAABAoGvU5M+Hh4fryyy/VpUsXr/p/++23ioqKUk5Ojm699VYZYxQXF6dJkyZpypQpkiSXy6Xo6Gi9/vrreuKJJy55TJ4zAwCA9Vj2OTPl5eWSpMjISElSYWGhSkpKNHToUHcfu92uAQMGaNOmTbUew+Vyyel0emwAACB4BUyYMcZo8uTJuvnmm9WzZ09JUklJiSQpOjrao290dLR734UyMzPlcDjcW3x8fOMWDgAA/MrrMDN58mT3Wpbc3FydOXPmku+55ZZbFBoa6tXxn376ae3YsUN/+MMfauy78GF9xpg6H+A3depUlZeXu7eioiKvzg8AAKzJ6zDzm9/8xv3jkoMGDfLqlut169YpNjb2kv3Gjx+vtWvXauPGjerUqZO7PSYmRpJqzMKUlpbWmK05x263KyIiwmMDAADBy+uH5nXu3Flvv/22hg4dKmOMNm/erHbt2tXa99Zbb/XqmMYYjR8/XqtXr1Z2drYSExM99icmJiomJkZZWVnq06ePJKmqqko5OTl6/fXXvS0dAAAEMa/vZlqzZo3Gjh2r0tJS2Wy2Op8hY7PZVF1d7dXJn3rqKS1btkzvv/++rrnmGne7w+FwX556/fXXlZmZqYULFyopKUnTp09Xdna2CgoKFB4efslzcDcTAADWU5/v73rfml1RUaGIiAgVFBQoKiqq1j4Oh8OrY9W17mXhwoUaM2aMpO9nb15++WW9++67KisrU79+/fTOO++4FwlfCmEGAADraZQwM3nyZL3yyitq06aNcnJydNNNN6lFC6+vUvkNYQYAAOtplOfMnL8A+LbbbuM3lwAAQEDw6wJgAACAy+XXBcBNgctMAABYj2UWADcFwgwAANZTn+/veq/gDQsL08aNG5WYmGiJBcAAACC4eZ1GnE6nOxn16dNHp06dqrMvMyAAAKCpeB1m2rVrp+LiYkVFRalt27a1PiPm3G8mBdKaGQAAENy8DjMbNmxQZGSkJGnjxo2NVhAAAEB91HsBsNWwABgAAOtplAXAO3bs8LqA5ORkr/sCAABcDq/DTO/evd3Pl6nrN5XOYc0MAABoKl7/nEFhYaEOHjyowsJCrVy5UomJiZozZ462b9+u7du3a86cOeratatWrlzZmPUCAAB48HpmJiEhwf33gw8+qLffflt33XWXuy05OVnx8fF68cUXde+99zZokQAAAHXxembmfPn5+UpMTKzRnpiYqN27d192UQAAAN7yKcx0795dr776qr777jt3m8vl0quvvqru3bs3WHEAAACX4tPvEcybN0/Dhw9XfHy8evXqJUn68ssvZbPZ9Oc//7lBCwQAALgYn58zc+rUKS1dulRfffWVjDHq0aOHRo0apTZt2jR0jZeF58wAAGA9jfpDk+e0bt1aP/vZzy7aZ9iwYXrvvfcUGxvr62kAAAAuyqc1M97Kzc3V6dOnG/MUAADgCteoYQYAAKCxEWYAAIClEWYAAIClEWYAAIClEWYAAIClNWqYmTZtmiIjIxvzFAAA4ArnU5hZvHixPvjgA/fr5557Tm3btlVaWpoOHz7sbp86daratm172UUCAADUxacwM336dIWGhkqSNm/erNmzZ2vmzJnq0KGDfv7znzdogQAAABfj0xOAi4qK1K1bN0nSmjVr9MADD+hnP/uZbrrpJg0cOLAh6wMAALgon2ZmwsLCdOzYMUnS+vXrdfvtt0uSWrVqxRN/AQBAk/JpZmbIkCF67LHH1KdPH+3du1fDhg2TJO3atUudO3duyPoAAAAuyqeZmXfeeUf9+/fXt99+q5UrV6p9+/aSpG3btumhhx7y+ji5ubkaPny44uLiZLPZtGbNGo/9Y8aMkc1m89hSU1N9KRkAAAQpn2Zm2rZtq9mzZ9dof/nll+t1nMrKSvXq1Us/+clPNGLEiFr73HnnnVq4cKH7dUhISP2KBQAAQc2nMCNJZWVl+u1vf6s9e/bIZrPp2muv1aOPPlqv58qkp6crPT39on3sdrtiYmJ8LRMAAAQ5ny4z5eTkqHPnznr77bdVVlam48eP6ze/+Y0SExOVk5PToAVmZ2crKipKV199tR5//HGVlpZetL/L5ZLT6fTYAABA8LIZY0x939SzZ0+lpaVp7ty5at68uSSpurpaTz31lD777DPt3Lmz/oXYbFq9erXuvfded9uKFSsUFhamhIQEFRYW6sUXX9SZM2e0bds22e32Wo+TkZFR6+Wu8vJyRURE1LsuAADQ9JxOpxwOh1ff3z6FmdDQUOXl5emaa67xaC8oKFDv3r19uj27tjBzoeLiYiUkJGj58uW6//77a+3jcrnkcrncr51Op+Lj4wkzAABYSH3CjE9rZm644Qbt2bOnRpjZs2ePevfu7cshvRIbG6uEhATt27evzj52u73OWRsAABB8vA4zO3bscP89YcIETZw4Ufv373ffKr1lyxa98847mjFjRsNX+b+OHTumoqIixcbGNto5AACAtXh9malZs2ay2Wy6VHebzabq6mqvTl5RUaH9+/dLkvr06aNZs2Zp0KBBioyMVGRkpDIyMjRixAjFxsbq0KFDmjZtmo4cOaI9e/YoPDzcq3PUZ5oKAAAEhka5zFRYWHjZhV3oiy++0KBBg9yvJ0+eLEkaPXq05s6dq/z8fC1ZskQnTpxQbGysBg0apBUrVngdZAAAQPDzaQHwObt379aRI0dUVVX1fwe02TR8+PAGKa4hMDMDAID1NPoC4IMHD+q+++5Tfn6+x6Unm80mSV5fZgIAALhcPj00b+LEiUpMTNQ333yj1q1ba+fOncrNzVVKSoqys7MbuEQAAIC6+TQzs3nzZm3YsEEdO3ZUs2bN1Lx5c918883KzMzUhAkTtH379oauEwAAoFY+zcxUV1crLCxMktShQwd9/fXXkqSEhAQVFBQ0XHUAAACX4NPMTM+ePbVjxw516dJF/fr108yZMxUSEqL58+erS5cuDV0jAABAnXwKMy+88IIqKyslSa+++qruvvtu3XLLLWrfvr1WrFjRoAUCAABczGXdmn2+48ePq127du47mgIFt2YDAGA9jX5rdm0iIyMb6lAAAABe82kBMAAAQKAgzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEsjzAAAAEvza5jJzc3V8OHDFRcXJ5vNpjVr1njsN8YoIyNDcXFxCg0N1cCBA7Vr1y7/FAsAAAKSX8NMZWWlevXqpdmzZ9e6f+bMmZo1a5Zmz56trVu3KiYmRkOGDNHJkyebuFIAABCoWvjz5Onp6UpPT691nzFGb775pp5//nndf//9kqTFixcrOjpay5Yt0xNPPNGUpQIAgAAVsGtmCgsLVVJSoqFDh7rb7Ha7BgwYoE2bNtX5PpfLJafT6bEBAIDgFbBhpqSkRJIUHR3t0R4dHe3eV5vMzEw5HA73Fh8f36h1AgAA/wrYMHOOzWbzeG2MqdF2vqlTp6q8vNy9FRUVNXaJAADAj/y6ZuZiYmJiJH0/QxMbG+tuLy0trTFbcz673S673d7o9QEAgMAQsDMziYmJiomJUVZWlrutqqpKOTk5SktL82NlAAAgkPh1ZqaiokL79+93vy4sLFReXp4iIyN11VVXadKkSZo+fbqSkpKUlJSk6dOnq3Xr1ho1apQfqwYAAIHEr2Hmiy++0KBBg9yvJ0+eLEkaPXq0Fi1apOeee06nT5/WU089pbKyMvXr10/r169XeHi4v0oGAAABxmaMMf4uojE5nU45HA6Vl5crIiLC3+UAAAAv1Of7O2DXzAAAAHiDMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACwt4MNMRkaGbDabxxYTE+PvsgAAQIBo4e8CvHHdddfpk08+cb9u3ry5H6sBAACBxBJhpkWLFszGAACAWgX8ZSZJ2rdvn+Li4pSYmKgf//jHOnjwoL9LAgAAASLgZ2b69eunJUuW6Oqrr9Y333yjV199VWlpadq1a5fat29fo7/L5ZLL5XK/djqdTVkuAABoYjZjjPF3EfVRWVmprl276rnnntPkyZNr7M/IyNDLL79co728vFwRERFNUSIAALhMTqdTDofDq+9vS1xmOl+bNm10/fXXa9++fbXunzp1qsrLy91bUVFRE1cIAACaUsBfZrqQy+XSnj17dMstt9S63263y263N3FVAADAXwJ+ZubZZ59VTk6OCgsL9be//U0PPPCAnE6nRo8e7e/SAABAAAj4mZl//OMfeuihh3T06FF17NhRqamp2rJlixISEvxdGgAACAABH2aWL1/u7xIAAEAAC/jLTAAAABdDmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJZGmAEAAJbWwt8FBJuD31bo8PFT6ty+jRI7tPF3OQAABD3CTAM5capKE/6Qp9x937rbbk3qqN881EeO1i39WBkAAMGNy0wN5Mmlf/cIMpKUu+9bjV26zU8VAQBwZSDMNICD31Zo88Fjte7bfPCYCo9WNnFFAABcObjMdBkOfluhvxUe0+eFZRftt+XgMdbPAADQSCwxMzNnzhwlJiaqVatW6tu3rz799FO/1nPiVJVGLdii236do6mrdmr19n9etL+tieoCAOBKFPBhZsWKFZo0aZKef/55bd++XbfccovS09N15MgRv9XU+5dZ2nSg9stKtenXpX0jVgMAwJUt4MPMrFmz9NOf/lSPPfaYunfvrjfffFPx8fGaO3euX+o5+G1FvfqndW3PJSYAABpRQIeZqqoqbdu2TUOHDvVoHzp0qDZt2uSXmm77dY7XfW9N6qi5D/dtxGoAAEBALwA+evSoqqurFR0d7dEeHR2tkpKSWt/jcrnkcrncr51OZ6PWWJeNzw5kRgYAgCYQ0DMz59hsnktojTE12s7JzMyUw+Fwb/Hx8U1RYg0EGQAAmkZAh5kOHTqoefPmNWZhSktLa8zWnDN16lSVl5e7t6KioqYo1cOvHkhu8nMCAHClCugwExISor59+yorK8ujPSsrS2lpabW+x263KyIiwmNrSIdmDLtknwdT/DMbBADAlSig18xI0uTJk/XII48oJSVF/fv31/z583XkyBGNHTvW36XVat34m/1dAgAAV5SADzMjR47UsWPH9Mtf/lLFxcXq2bOn1q1bp4SEBL/VdG52pvMvPnC3/eqBZGZkAADwA5sxxvi7iMbkdDrlcDhUXl7e4JecAABA46jP93dAr5kBAAC4FMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwNMIMAACwtID/babLde7XGpxOp58rAQAA3jr3ve3Nry4FfZg5efKkJCk+nh+BBADAak6ePCmHw3HRPkH/Q5Nnz57V119/rfDwcNlstgY9ttPpVHx8vIqKiq6YH7FkzIw5GF1p45UYM2MOfMYYnTx5UnFxcWrW7OKrYoJ+ZqZZs2bq1KlTo54jIiLCcv8juVyM+cpwpY35ShuvxJivFFYd86VmZM5hATAAALA0wgwAALA0wsxlsNvteumll2S32/1dSpNhzFeGK23MV9p4JcZ8pbhSxhz0C4ABAEBwY2YGAABYGmEGAABYGmEGAABYGmHGR3PmzFFiYqJatWqlvn376tNPP/V3SQ0mNzdXw4cPV1xcnGw2m9asWeOx3xijjIwMxcXFKTQ0VAMHDtSuXbv8U2wDyczM1I033qjw8HBFRUXp3nvvVUFBgUefYBv33LlzlZyc7H7+RP/+/fXhhx+69wfbeC+UmZkpm82mSZMmuduCccwZGRmy2WweW0xMjHt/MI75n//8p/7t3/5N7du3V+vWrdW7d29t27bNvT8Yx9y5c+ca/842m03jxo2TFJxj9mBQb8uXLzctW7Y0CxYsMLt37zYTJ040bdq0MYcPH/Z3aQ1i3bp15vnnnzcrV640kszq1as99s+YMcOEh4eblStXmvz8fDNy5EgTGxtrnE6nfwpuAHfccYdZuHCh2blzp8nLyzPDhg0zV111lamoqHD3CbZxr1271nzwwQemoKDAFBQUmGnTppmWLVuanTt3GmOCb7zn+/zzz03nzp1NcnKymThxors9GMf80ksvmeuuu84UFxe7t9LSUvf+YBvz8ePHTUJCghkzZoz529/+ZgoLC80nn3xi9u/f7+4TbGM2xpjS0lKPf+OsrCwjyWzcuNEYE5xjPh9hxgc//OEPzdixYz3arr32WvOLX/zCTxU1ngvDzNmzZ01MTIyZMWOGu+27774zDofDzJs3zw8VNo7S0lIjyeTk5Bhjrpxxt2vXzrz33ntBPd6TJ0+apKQkk5WVZQYMGOAOM8E65pdeesn06tWr1n3BOOYpU6aYm2++uc79wTjm2kycONF07drVnD179ooYM5eZ6qmqqkrbtm3T0KFDPdqHDh2qTZs2+amqplNYWKiSkhKP8dvtdg0YMCCoxl9eXi5JioyMlBT8466urtby5ctVWVmp/v37B/V4x40bp2HDhun222/3aA/mMe/bt09xcXFKTEzUj3/8Yx08eFBScI557dq1SklJ0YMPPqioqCj16dNHCxYscO8PxjFfqKqqSkuXLtWjjz4qm812RYyZMFNPR48eVXV1taKjoz3ao6OjVVJS4qeqms65MQbz+I0xmjx5sm6++Wb17NlTUvCOOz8/X2FhYbLb7Ro7dqxWr16tHj16BO14ly9frr///e/KzMyssS9Yx9yvXz8tWbJEH3/8sRYsWKCSkhKlpaXp2LFjQTnmgwcPau7cuUpKStLHH3+ssWPHasKECVqyZImk4P13Pt+aNWt04sQJjRkzRtKVMeag/6HJxnLhL3AbYxr8V7kDWTCP/+mnn9aOHTv017/+tca+YBv3Nddco7y8PJ04cUIrV67U6NGjlZOT494fTOMtKirSxIkTtX79erVq1arOfsE0ZklKT093/3399derf//+6tq1qxYvXqzU1FRJwTXms2fPKiUlRdOnT5ck9enTR7t27dLcuXP17//+7+5+wTTmC/32t79Venq64uLiPNqDeczMzNRThw4d1Lx58xpptrS0tEbqDUbn7oII1vGPHz9ea9eu1caNGz1+bT1Yxx0SEqJu3bopJSVFmZmZ6tWrl956662gHO+2bdtUWlqqvn37qkWLFmrRooVycnL09ttvq0WLFu5xBdOYa9OmTRtdf/312rdvX1D+O8fGxqpHjx4ebd27d9eRI0ckBe9/y+ccPnxYn3zyiR577DF3W7CPWSLM1FtISIj69u2rrKwsj/asrCylpaX5qaqmk5iYqJiYGI/xV1VVKScnx9LjN8bo6aef1qpVq7RhwwYlJiZ67A/WcV/IGCOXyxWU4x08eLDy8/OVl5fn3lJSUvTwww8rLy9PXbp0Cbox18blcmnPnj2KjY0Nyn/nm266qcZjFfbu3auEhARJwf/f8sKFCxUVFaVhw4a524J9zJK4NdsX527N/u1vf2t2795tJk2aZNq0aWMOHTrk79IaxMmTJ8327dvN9u3bjSQza9Yss337dvet5zNmzDAOh8OsWrXK5Ofnm4ceesjyt/g9+eSTxuFwmOzsbI/bG0+dOuXuE2zjnjp1qsnNzTWFhYVmx44dZtq0aaZZs2Zm/fr1xpjgG29tzr+byZjgHPMzzzxjsrOzzcGDB82WLVvM3XffbcLDw93/fxVsY/78889NixYtzGuvvWb27dtnfv/735vWrVubpUuXuvsE25jPqa6uNldddZWZMmVKjX3BOuZzCDM+euedd0xCQoIJCQkxN9xwg/sW3mCwceNGI6nGNnr0aGPM97c2vvTSSyYmJsbY7XZz6623mvz8fP8WfZlqG68ks3DhQnefYBv3o48+6v7fcMeOHc3gwYPdQcaY4BtvbS4MM8E45nPPE2nZsqWJi4sz999/v9m1a5d7fzCO+U9/+pPp2bOnsdvt5tprrzXz58/32B+MYzbGmI8//thIMgUFBTX2BeuYz+FXswEAgKWxZgYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQa4Qhw6dEg2m015eXl+OV92drZsNptOnDjh7rNmzRp169ZNzZs316RJk+psq8uiRYvUtm3bRqnfX+et7XMCcHGEGQBNIi0tTcXFxXI4HO62J554Qg888ICKior0yiuv1NkWaEaOHKm9e/e6X2dkZKh3797+Kwi4wrXwdwEArgwhISGKiYlxv66oqFBpaanuuOMOxcXF1dkWiEJDQxUaGurvMgD8L2ZmgCDy0Ucf6eabb1bbtm3Vvn173X333Tpw4IBHn6+++kppaWlq1aqVrrvuOmVnZ7v3lZWV6eGHH1bHjh0VGhqqpKQkLVy40Ktzf/755+rTp49atWqllJQUbd++3WP/+ZdPsrOzFR4eLkm67bbbZLPZ6myrr7lz56pr164KCQnRNddco//+7//22G+z2fTee+/pvvvuU+vWrZWUlKS1a9d69Fm7dq2SkpIUGhqqQYMGafHixR6Xfs6/zLRo0SK9/PLL+vLLL2Wz2WSz2bRo0aJaL+udOHGixrjWrVunq6++2n2uQ4cO1RjTpk2bdOuttyo0NFTx8fGaMGGCKisr6/3ZAEHL3790CaDh/PGPfzQrV640e/fuNdu3bzfDhw83119/vamurjaFhYVGkunUqZP54x//aHbv3m0ee+wxEx4ebo4ePWqMMWbcuHGmd+/eZuvWraawsNBkZWWZtWvXXvK8FRUVpmPHjmbkyJFm586d5k9/+pPp0qWLkWS2b99ujPm/X2MvKyszLpfLFBQUGElm5cqVpri4uM62i1m4cKFxOBzu16tWrTItW7Y077zzjikoKDC//vWvTfPmzc2GDRvcfc59BsuWLTP79u0zEyZMMGFhYebYsWPGGGMKCwtNy5YtzbPPPmu++uor84c//MH84Ac/cNd+4XlPnTplnnnmGXPdddeZ4uJiU1xcbE6dOuX+vM+N3xhjysrKjCSzceNGY4wxR44cMXa73UycONF89dVXZunSpSY6OtrjXDt27DBhYWHmjTfeMHv37jWfffaZ6dOnjxkzZswl/12AKwVhBghipaWlRpLJz893f7nOmDHDvf9f//qX6dSpk3n99deNMcYMHz7c/OQnP6n3ed59910TGRlpKisr3W1z586tM8wYU/OLva62i7kwzKSlpZnHH3/co8+DDz5o7rrrLvdrSeaFF15wv66oqDA2m818+OGHxhhjpkyZYnr27OlxjOeff77OMGOMMS+99JLp1auXx3u8CTNTp0413bt3N2fPnnX3mTJlise5HnnkEfOzn/3M49iffvqpadasmTl9+nSdnw1wJeEyExBEDhw4oFGjRqlLly6KiIhQYmKiJOnIkSPuPv3793f/3aJFC6WkpGjPnj2SpCeffFLLly9X79699dxzz2nTpk1enXfPnj3q1auXWrduXet5msqePXt00003ebTddNNN7vGdk5yc7P67TZs2Cg8PV2lpqSSpoKBAN954o0f/H/7wh41Wb2pqqmw2m7vtws9t27ZtWrRokcLCwtzbHXfcobNnz6qwsLBR6gKshgXAQBAZPny44uPjtWDBAsXFxens2bPq2bOnqqqqLvq+c1+m6enpOnz4sD744AN98sknGjx4sMaNG6f/+q//uuj7jTENNobLdX4wkL6v7cK2li1b1njP2bNn6+zvy/iaNWtW473/+te/6n3cs2fP6oknntCECRNq7LvqqqvqXRcQjJiZAYLEsWPHtGfPHr3wwgsaPHiwunfvrrKyshr9tmzZ4v77zJkz2rZtm6699lp3W8eOHTVmzBgtXbpUb775pubPn3/Jc/fo0UNffvmlTp8+Xet5mkr37t3117/+1aNt06ZN6t69u9fHuPbaa7V161aPti+++OKi7wkJCVF1dbVHW8eOHSVJxcXF7rYLn/HTo0ePGp/Tha9vuOEG7dq1S926dauxhYSEeDUmINgRZoAg0a5dO7Vv317z58/X/v37tWHDBk2ePLlGv3feeUerV6/WV199pXHjxqmsrEyPPvqoJOk///M/9f7772v//v3atWuX/vznP3sVBEaNGqVmzZrppz/9qXbv3q1169ZdcjanMfzHf/yHFi1apHnz5mnfvn2aNWuWVq1apWeffdbrYzzxxBP66quvNGXKFO3du1f/8z//o0WLFkmqOetzTufOnVVYWKi8vDwdPXpULpdLoaGhSk1N1YwZM7R7927l5ubqhRde8Hjf2LFjdeDAAU2ePFkFBQVatmyZ+1znTJkyRZs3b9a4ceOUl5enffv2ae3atRo/fny9PhsgqPlzwQ6AhpWVlWW6d+9u7Ha7SU5ONtnZ2UaSWb16tXtB6rJly0y/fv1MSEiI6d69u/nLX/7ifv8rr7xiunfvbkJDQ01kZKS55557zMGDB7069+bNm02vXr1MSEiI6d27t1m5cmWTLwA2xpg5c+aYLl26mJYtW5qrr77aLFmyxGP/uc/jfA6HwyxcuND9+v333zfdunUzdrvdDBw40L2Y+dyC2wvP+91335kRI0aYtm3bGknuY+3evdukpqaa0NBQ07t3b7N+/foa4/vTn/7kPtctt9xifve733l8TsYY8/nnn5shQ4aYsLAw06ZNG5OcnGxee+01rz4j4EpgMyaALnYDQAB67bXXNG/ePBUVFfm7FAC1YAEwAFxgzpw5uvHGG9W+fXt99tln+tWvfqWnn37a32UBqANrZgBc0vTp0z1uDT5/S09Pb7Tzpqen13ne6dOnN9p59+3bp3vuuUc9evTQK6+8omeeeUYZGRmNdj4Al4fLTAAu6fjx4zp+/Hit+0JDQ/WDH/ygUc77z3/+0+MOqfNFRkYqMjKyUc4LwFoIMwAAwNK4zAQAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACyNMAMAACzt/wPTI/LDuIWqSQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "plot = train_df.iloc[:2000].plot.scatter('abs_diff_longitude', 'abs_diff_latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1a641",
   "metadata": {},
   "source": [
    "70 degrees longitude seems a bit too high..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ac95e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old size: 9999926\n",
      "New size: 9979189\n",
      "CPU times: user 645 ms, sys: 190 ms, total: 835 ms\n",
      "Wall time: 830 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Old size: %d' % len(train_df))\n",
    "train_df = train_df[(train_df.abs_diff_longitude < 5.0) & (train_df.abs_diff_latitude < 5.0)]\n",
    "print('New size: %d' % len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3a4eea",
   "metadata": {},
   "source": [
    "#### Get training features and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1ca5802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9979189, 3)\n",
      "(9979189,)\n",
      "CPU times: user 116 ms, sys: 46.2 ms, total: 162 ms\n",
      "Wall time: 159 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "\n",
    "# using the travel vector, plus a 1.0 for a constant bias term.\n",
    "def get_input_matrix(df):\n",
    "    return np.column_stack((df.abs_diff_longitude, df.abs_diff_latitude, np.ones(len(df))))\n",
    "\n",
    "train_X = get_input_matrix(train_df)\n",
    "train_y = np.array(train_df['fare_amount'])\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836ce60e",
   "metadata": {},
   "source": [
    "#### Train a simple linear model using Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4d698bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148.48697     74.73346376   6.41299165]\n",
      "CPU times: user 892 ms, sys: 674 ms, total: 1.57 s\n",
      "Wall time: 835 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The lstsq function returns several things, and we only care about the actual weight vector w.\n",
    "(w, _, _, _) = np.linalg.lstsq(train_X, train_y, rcond = None)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b46de57",
   "metadata": {},
   "source": [
    "#### Make prediction on our test set and measure performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cab29b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0              int64\n",
       "key                    object\n",
       "fare_amount           float64\n",
       "pickup_datetime        object\n",
       "pickup_longitude      float64\n",
       "pickup_latitude       float64\n",
       "dropoff_longitude     float64\n",
       "dropoff_latitude      float64\n",
       "passenger_count         int64\n",
       "abs_diff_longitude    float64\n",
       "abs_diff_latitude     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df =  pd.read_csv('gs://obd-dask23/test_cleaned.csv', storage_options={'token': 'anon'})\n",
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6c9d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_travel_vector_features(test_df)\n",
    "test_X = get_input_matrix(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5cf989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_predictions = np.matmul(test_X, w).round(decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83a1d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_ref = test_df.fare_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b22f5728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.428124794105603"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(test_y_ref, test_y_predictions, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c732df4",
   "metadata": {},
   "source": [
    "You should get sabout 6.43 of RMSE, not bad, but we can do better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78fdd59",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "### Some questions on this first Analysis\n",
    "\n",
    "- What is the most expensive part of the analysis, the one that takes the most time (see the %%time we used above)?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea301550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataframe with pandas was the most expensive part of this analysis, since it lasted about 46 seconds (wall time, and 35 seconds on CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e331b7",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Try to load the whole dataset with Pandas and comment what happens. Can you explain why?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42190bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#train_df =  pd.read_csv('gs://obd-dask23/train.csv', storage_options={'token': 'anon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a22544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The input data is just too big to fit inside memory. That is why our kernel crashed.\n",
    "#I commented the line above to avoid another crash by accident"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f478f17c",
   "metadata": {},
   "source": [
    "# Processing our data set using Dask\n",
    "\n",
    "Dask will help us process all the input data set at once. It is really useful when input data is too big to fit in memory. In this case, it can stream the computation by data chunks on one computer, or distribute the computation on several computers.\n",
    "\n",
    "This is what we'll do next!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c22aeb",
   "metadata": {},
   "source": [
    "### Start an appropriately sized Dask cluster for our analysis\n",
    "\n",
    "We'll need a Dask cluster to pre process the data and distribute some learning, the following code starts one in our K8S infrastructure.\n",
    "\n",
    "**Be sure to have any other Dask cluster shutdown.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62d7d4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_gateway import Gateway\n",
    "gateway = Gateway()\n",
    "clusters=gateway.list_clusters()\n",
    "for cluster in clusters:\n",
    "    gateway.stop_cluster(cluster.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93f18fc8-fa16-490f-9a39-033d1829ead7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2aeca3be7545a5aeee60300a15662d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>GatewayCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n<style scoped>\\n    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster = gateway.new_cluster(worker_cores=1, worker_memory=3.0)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a329c1",
   "metadata": {},
   "source": [
    "__Please click on the Dashboard link above, it will help you a lot!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f38dac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f33cbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:30:08,797 - distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n"
     ]
    }
   ],
   "source": [
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992aba71",
   "metadata": {},
   "source": [
    "### Launch some computation, what about Pi?\n",
    "\n",
    "Just to check our cluster is working!\n",
    "\n",
    "We'll use Dask array, a Numpy extension for this, we'll also use it later on for the Machine Learning part of this evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "893cedb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi ~= 3.1415999876\n",
      "CPU times: user 807 ms, sys: 119 ms, total: 927 ms\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import dask.array as da\n",
    "\n",
    "sample = 10_000_000_000  # <- this is huge!\n",
    "xxyy = da.random.uniform(-1, 1, size=(2, sample))\n",
    "norm = da.linalg.norm(xxyy, axis=0)\n",
    "summ = da.sum(norm <= 1)\n",
    "insiders = summ.compute()\n",
    "pi = 4 * insiders / sample\n",
    "print(\"pi ~= {}\".format(pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc0fd7e",
   "metadata": {},
   "source": [
    "## Now, access the data of our BE using Dask\n",
    "\n",
    "We'll use Dask Dataframe, a distributed version of Pandas Dataframe.\n",
    "\n",
    "Remember, Dask shares the same API as Pandas.\n",
    "\n",
    "See https://docs.dask.org/en/latest/dataframe.html.\n",
    "\n",
    "<br>\n",
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "So instead of using Pandas to load the dataset, just use the equivalent dask method from dask.dataframe.\n",
    "\n",
    "- Fill the following cell (the second one) with the appropriate code to read the data using Dask.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e2fe6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6905e21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 273 ms, sys: 68.7 ms, total: 342 ms\n",
      "Wall time: 453 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df=dd.read_csv('gs://obd-dask23/train.csv', storage_options={'token': 'anon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "178c1003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=89</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>string</td>\n",
       "      <td>float64</td>\n",
       "      <td>string</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: to_pyarrow_string, 2 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                   key fare_amount pickup_datetime pickup_longitude pickup_latitude dropoff_longitude dropoff_latitude passenger_count\n",
       "npartitions=89                                                                                                                        \n",
       "                string     float64          string          float64         float64           float64          float64           int64\n",
       "                   ...         ...             ...              ...             ...               ...              ...             ...\n",
       "...                ...         ...             ...              ...             ...               ...              ...             ...\n",
       "                   ...         ...             ...              ...             ...               ...              ...             ...\n",
       "                   ...         ...             ...              ...             ...               ...              ...             ...\n",
       "Dask Name: to_pyarrow_string, 2 graph layers"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c5362",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "### Some questions about this data loading\n",
    "\n",
    "- That was fast for several gigabytes, wasn't it? Why is this, did we really load all the data?\n",
    "- Why the returned dataframe looks empty?\n",
    "- See the number of partitions described above? What does it correspond to? (hint, look at the blocksize parameter from https://docs.dask.org/en/latest/generated/dask.dataframe.read_csv.html). You might also get a more precise idea of what this number corresponds to with the next code execution.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a933388-9149-4720-afb7-853ab75c67b7",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "Dask adopt a lazy evaluation model. It means that when you load data into a Daska df, Daks doesn't immediately load the data into memory. Instead, it creates a task graph that describes the operation needed to load the data. The graph is only executer when you explicitly ask for the result of a computation (by calling .compute()). That's why the dataframe look empty. In a sense however, we really loaded the data, since Dask has prepared a plan to load the data when needed. But no in the sense that the data is not yet in memory. The loading only happens when necessary during computation.\n",
    "\n",
    "When we have loaded our data into a Dask df, it got divided into smaller partitions (chunks), each corresponding to a block of data. These partitions allow Dask to parallelize computations accross the dataset, making it suitable for distributed and out-of-core processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6834c674",
   "metadata": {},
   "source": [
    "## Little warm up: Analyzing our data to better understand it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc8f8e",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "- First, how many records do we have? (hint, in python, len() works for almost any object).\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eff99939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.6 ms, sys: 7.32 ms, total: 62 ms\n",
      "Wall time: 42 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55413856"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "len(train_df)\n",
    "#It looks like we have 55 413 856 records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1980192c",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- What did happend when counting record of our Dask dataframe (as opposed to with only the `read_csv` call? Remember with the Spark tutorial: transformations and actions... Same kind of concepts exist in Dask. Just look at the Dask Dashboard!\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8fd5c5-3def-4638-bac6-5fc765585bce",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "When you count the number of records in a Dask DataFrame, you're moving beyond just setting up a computation (as with the read_csv call) and actually triggering the computation to run. This distinction between setting up computations and executing them is indeed similar to the concept of transformations and actions in Spark. In Dask, this is often referred to as the difference between lazy evaluation and eager execution. \n",
    "\n",
    "**Transformations** are operations that don't compute results immediately, but instead build up a task graph (like we did when calling read_csv, but also filtering, grouping...). These operations are lazy, like we previously explained, because they don't trigger any actual data processing, they just prepare the computation plan.\n",
    "\n",
    "**Actions** are operations that trigger computation and produce results (such as .compute()). When performing actions in Dask, it executes the task graph previously built by the transformation and then actually process the data.\n",
    "\n",
    "Looking at our dashboard, we see that calling len(train_df) did load the necessary data into memory, processing it in partitions to keep memory usage manageable, then executing the taks graph, then aggregating the count results of the different parts (this operation is also part of the task graph), and finally returning the result (the number of record in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668942d8",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Compare the time of this computation to the time of loading a subset of the Dataset with Pandas. Was it fast enough considering the number of workers we have?\n",
    "    \n",
    "I recommend trying to calculate an estimation of the time it would take with Pandas to read the entire dataset, and **total processing** time (not only the walltime) it took for every dask workers.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2025840-3ce6-4c2e-a689-2a76347bc680",
   "metadata": {},
   "source": [
    "**ANSWER** \n",
    "\n",
    "In order to load 20% of the dataset earlier, it took us about 45 seconds with walltime. If we multiply it by 5, we estimate it would have taken us 225 seconds, or 3.75 minutes to load the full dataset.\n",
    "For the Dask dataset, we look at the total processing time (summing user and sys), which brings us to 60s. We used 10 workers. Theoretically, this operation should execute in 225/10=25 seconds, but that did not happen. Why ? Because of what is called *Overhead*, meaning the theoretical perfect speed-up is never attained because of task scheduling, data partitioning, aggregating and communication between workers.\n",
    "Even if we did not speed-up the computation by a factor 10, we did it with a factor 2, which is still pretty good. Maybe we could have increased a little bit the number of worker to improve performance (but this is not sure). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e0f615",
   "metadata": {},
   "source": [
    "Let's have a look at some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cba28ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.28 s, sys: 561 ms, total: 2.84 s\n",
      "Wall time: 2.98 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-10-12 23:47:39.0000002</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2014-10-12 23:47:39 UTC</td>\n",
       "      <td>-73.973863</td>\n",
       "      <td>40.764248</td>\n",
       "      <td>-73.986874</td>\n",
       "      <td>40.736618</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-08-17 22:34:00.000000118</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2012-08-17 22:34:00 UTC</td>\n",
       "      <td>-73.997062</td>\n",
       "      <td>40.722330</td>\n",
       "      <td>-73.997642</td>\n",
       "      <td>40.729135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-05-17 13:11:00.000000229</td>\n",
       "      <td>9.70</td>\n",
       "      <td>2011-05-17 13:11:00 UTC</td>\n",
       "      <td>-74.000002</td>\n",
       "      <td>40.727167</td>\n",
       "      <td>-73.984253</td>\n",
       "      <td>40.753135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-08 09:10:25.0000005</td>\n",
       "      <td>57.33</td>\n",
       "      <td>2015-03-08 09:10:25 UTC</td>\n",
       "      <td>-74.004166</td>\n",
       "      <td>40.737652</td>\n",
       "      <td>-73.795753</td>\n",
       "      <td>40.644497</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-27 19:54:44.0000001</td>\n",
       "      <td>7.30</td>\n",
       "      <td>2010-03-27 19:54:44 UTC</td>\n",
       "      <td>-73.990309</td>\n",
       "      <td>40.751309</td>\n",
       "      <td>-73.980597</td>\n",
       "      <td>40.761481</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             key  fare_amount          pickup_datetime  \\\n",
       "0    2014-10-12 23:47:39.0000002         9.00  2014-10-12 23:47:39 UTC   \n",
       "1  2012-08-17 22:34:00.000000118         4.10  2012-08-17 22:34:00 UTC   \n",
       "2  2011-05-17 13:11:00.000000229         9.70  2011-05-17 13:11:00 UTC   \n",
       "3    2015-03-08 09:10:25.0000005        57.33  2015-03-08 09:10:25 UTC   \n",
       "4    2010-03-27 19:54:44.0000001         7.30  2010-03-27 19:54:44 UTC   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.973863        40.764248         -73.986874         40.736618   \n",
       "1        -73.997062        40.722330         -73.997642         40.729135   \n",
       "2        -74.000002        40.727167         -73.984253         40.753135   \n",
       "3        -74.004166        40.737652         -73.795753         40.644497   \n",
       "4        -73.990309        40.751309         -73.980597         40.761481   \n",
       "\n",
       "   passenger_count  \n",
       "0                1  \n",
       "1                1  \n",
       "2                2  \n",
       "3                2  \n",
       "4                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84867e4",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Why was it faster than counting all the records above? \n",
    "- What did we actualy read? You might want to look at the Dashboard for some hinsights. Remember that Dask laziness is not only about transformations and actions, but optimizing the computations needed.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c852e0-41d8-41e5-9b41-989cc96ed932",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "It was much faster than counting all the records ! When looking at the dashboard, we can see that only one worker was called with a to_pyarrow_string task. It is a method known to convert different objects (such as ou dataset first 5 rows) into string in a noticable really fast why. This method was probably chosen on purpose in order to accelerate the computation, highlighting the optimization of computation at all levels. When looking at this task into details, we notice that in the end, strings ar finally casted back to their original type with the .astype() method.\n",
    "Also, it is pretty clear that loading only the first five lines of the dataset should be much faster than crawling all its records like the len() method forced us to do. We took advantage of the partition into chunks in order to optimize computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81342f11",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Let's compute the mean of the fare amount given the passengers count, **as we've done with Pandas above**. Please fill the blank. (hint: Dask is the same as pandas, but often with a `compute()` call at the end)\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c56ddf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 65.8 ms, sys: 8.61 ms, total: 74.4 ms\n",
      "Wall time: 41.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "passenger_count\n",
       "0       9.015400\n",
       "1      11.216398\n",
       "2      11.838426\n",
       "3      11.540684\n",
       "4      11.766121\n",
       "5      11.208482\n",
       "6      12.126306\n",
       "8      29.981111\n",
       "208     8.975000\n",
       "51      9.300000\n",
       "129     8.900000\n",
       "7      31.788667\n",
       "9      36.993043\n",
       "34     13.300000\n",
       "49      2.500000\n",
       "Name: fare_amount, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_df.groupby(train_df.passenger_count).fare_amount.mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121f1dbf",
   "metadata": {},
   "source": [
    "Wow, ever seen a cab with more than **200 people**?? Americans are crazy. And it's cheap...\n",
    "\n",
    "<br>\n",
    "\n",
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "- This computation is slow, especially compared with Pandas, why? (Look a the Dashboard, again).\n",
    "- Which part of the computation is slow, look at the Dashboard to see the name of the tasks. Hint, this is the same as Pandas.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c2e0d9-5aed-44da-b3b5-65e433a8c647",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "Dask breaks down computation into tasks that can be executed in parallel. However, scheduling and managing these tasks introduce overhead (as we specified before). For operations that are not highly compute-intensive, the overhead of task management can outweight the benefits of parallel execution. There's an inherent cost in moving data between worked, this is particularly important for group-by operations, which may require significant data shuffling to group records by keys before computing the mean. Pandas operates in-memory and is highly optimized for single-threaded performance. For datasets that fit into memory, Pandas can often perform computations like group-by and mean very quickly. The simplicity of operating in a single process without the need to manage parallel tasks or handle data distribution can make Pandas faster for these types of operations.\n",
    "\n",
    "When looking at the dashboard, our hypothese is confirmed : the worst-performing (taking longer) task is the .getItem() method. The groupby-count-chunk and groupby-sum-chunk did only take 2 seconds, while the getItem did take 272 seconds (partitionned between all workers). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff37ce7",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- How could we optimize the next computations, using which Dask method? Same as Spark...\n",
    "- Where will be the data at the end of the computation triggered by this call?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c314cb9-1293-4aec-bd81-27e376c62419",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "To optimize computations in Dask, especially for operations executed repeatedly, or requiring significant data shuffling ( such as group-by), we can use the persist method. This approach is similar to what we did previously with Spark, and can significantly improve performance for iterative computation or when needing to access the same dataset multiple times. \n",
    "The persist method evaluates the computation up to the current point, and keeps the resulting dataset in memory (or on disk) accross the cluster. After calling persist, the dataset will be kept in distributed memory accross the cluster's workers, and subsequent operations (transformations, actions), will be much faster. Any future computation of the persisted data will start from the in-memory state of the data. \n",
    "\n",
    "**REMARK** : I WILL NOT USE THE PERSIST ON THE FULL DATASET, since it makes my server crash because of limitations on the persistent disk quota in google cloud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26f10c20-82ec-49d9-a16e-a7353a506cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=dd.read_csv('gs://obd-dask23/train.csv', storage_options={'token': 'anon'}).persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49397217",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Look at the Dashboard at what is happening beind the scene.\n",
    "    \n",
    "Wait for the end of this call on the Dashboard, then try again the previous computation on fare_amout.mean():\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a9fa8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 110 ms, sys: 14.3 ms, total: 124 ms\n",
      "Wall time: 34.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "passenger_count\n",
       "0       9.015400\n",
       "1      11.216398\n",
       "2      11.838426\n",
       "3      11.540684\n",
       "4      11.766121\n",
       "5      11.208482\n",
       "6      12.126306\n",
       "8      29.981111\n",
       "208     8.975000\n",
       "51      9.300000\n",
       "129     8.900000\n",
       "7      31.788667\n",
       "9      36.993043\n",
       "34     13.300000\n",
       "49      2.500000\n",
       "Name: fare_amount, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_df.groupby(train_df.passenger_count).fare_amount.mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddadf8d3",
   "metadata": {},
   "source": [
    "Much better isn't it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bf8179",
   "metadata": {},
   "source": [
    "## Let's do some preprocessing of our data to clean it up and add some features\n",
    "\n",
    "<br>\n",
    "\n",
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "- You'll need to do the same operations as in pandas, we just need to call compute when needing a result, and not compute when building our dataframe transformations.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adffd39",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "#### Cleaning up\n",
    "\n",
    "- Is there some null values in our data?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fbea246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key                    0\n",
      "fare_amount            0\n",
      "pickup_datetime        0\n",
      "pickup_longitude       0\n",
      "pickup_latitude        0\n",
      "dropoff_longitude    376\n",
      "dropoff_latitude     376\n",
      "passenger_count        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50fd4c3",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Yep! We must get rid of them...\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2ff9453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 ms, sys: 1.66 ms, total: 12.2 ms\n",
      "Wall time: 11.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = train_df.dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8379f88-43cd-459b-9aa4-5aea332c2931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key                  0\n",
      "fare_amount          0\n",
      "pickup_datetime      0\n",
      "pickup_longitude     0\n",
      "pickup_latitude      0\n",
      "dropoff_longitude    0\n",
      "dropoff_latitude     0\n",
      "passenger_count      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a1f1b5",
   "metadata": {},
   "source": [
    "#### Adding features\n",
    "\n",
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "- As with Pandas above, add the latitude and longitude distance vector with a function call\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a108c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Answer needed here. We define a function here, cause we'll need to apply it on our test dataframe too later on!\n",
    "def add_travel_vector_features(df):\n",
    "    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n",
    "    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n",
    "\n",
    "add_travel_vector_features(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162dafb7",
   "metadata": {},
   "source": [
    "A quick look at our Dataframe to check things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13573f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>abs_diff_longitude</th>\n",
       "      <th>abs_diff_latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-10-12 23:47:39.0000002</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2014-10-12 23:47:39 UTC</td>\n",
       "      <td>-73.973863</td>\n",
       "      <td>40.764248</td>\n",
       "      <td>-73.986874</td>\n",
       "      <td>40.736618</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013011</td>\n",
       "      <td>0.027630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-08-17 22:34:00.000000118</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2012-08-17 22:34:00 UTC</td>\n",
       "      <td>-73.997062</td>\n",
       "      <td>40.722330</td>\n",
       "      <td>-73.997642</td>\n",
       "      <td>40.729135</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.006805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-05-17 13:11:00.000000229</td>\n",
       "      <td>9.70</td>\n",
       "      <td>2011-05-17 13:11:00 UTC</td>\n",
       "      <td>-74.000002</td>\n",
       "      <td>40.727167</td>\n",
       "      <td>-73.984253</td>\n",
       "      <td>40.753135</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015749</td>\n",
       "      <td>0.025968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-08 09:10:25.0000005</td>\n",
       "      <td>57.33</td>\n",
       "      <td>2015-03-08 09:10:25 UTC</td>\n",
       "      <td>-74.004166</td>\n",
       "      <td>40.737652</td>\n",
       "      <td>-73.795753</td>\n",
       "      <td>40.644497</td>\n",
       "      <td>2</td>\n",
       "      <td>0.208412</td>\n",
       "      <td>0.093155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-27 19:54:44.0000001</td>\n",
       "      <td>7.30</td>\n",
       "      <td>2010-03-27 19:54:44 UTC</td>\n",
       "      <td>-73.990309</td>\n",
       "      <td>40.751309</td>\n",
       "      <td>-73.980597</td>\n",
       "      <td>40.761481</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009712</td>\n",
       "      <td>0.010172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             key  fare_amount          pickup_datetime  \\\n",
       "0    2014-10-12 23:47:39.0000002         9.00  2014-10-12 23:47:39 UTC   \n",
       "1  2012-08-17 22:34:00.000000118         4.10  2012-08-17 22:34:00 UTC   \n",
       "2  2011-05-17 13:11:00.000000229         9.70  2011-05-17 13:11:00 UTC   \n",
       "3    2015-03-08 09:10:25.0000005        57.33  2015-03-08 09:10:25 UTC   \n",
       "4    2010-03-27 19:54:44.0000001         7.30  2010-03-27 19:54:44 UTC   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.973863        40.764248         -73.986874         40.736618   \n",
       "1        -73.997062        40.722330         -73.997642         40.729135   \n",
       "2        -74.000002        40.727167         -73.984253         40.753135   \n",
       "3        -74.004166        40.737652         -73.795753         40.644497   \n",
       "4        -73.990309        40.751309         -73.980597         40.761481   \n",
       "\n",
       "   passenger_count  abs_diff_longitude  abs_diff_latitude  \n",
       "0                1            0.013011           0.027630  \n",
       "1                1            0.000580           0.006805  \n",
       "2                2            0.015749           0.025968  \n",
       "3                2            0.208412           0.093155  \n",
       "4                1            0.009712           0.010172  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7cfc5f",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Now let's quickly plot a subset of our travel vector features to see its distribution. Use dask.dataframe.sample() to get about 1 percent of the rows, and get it back with compute and plot as we've done it with Pandas\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09f457c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 7.39 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-95' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-112' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-96' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-97' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-98' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-99' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-100' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-101' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-102' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-103' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-104' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-105' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-106' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-107' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-108' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-109' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-110' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-111' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-113' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-114' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-115' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-116' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-117' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-118' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-119' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-120' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-121' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-122' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-123' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-124' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-125' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-126' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-127' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-128' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-129' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-130' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-131' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-132' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-133' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-134' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-135' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-136' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-137' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-138' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-139' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-140' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-141' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-142' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-143' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-144' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-145' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-146' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-147' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-148' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-149' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-150' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-151' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-152' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-153' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-154' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-155' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-156' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-157' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-158' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-159' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-160' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-161' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-162' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-163' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-164' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-165' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-166' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-167' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-168' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-169' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-170' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-171' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-172' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-173' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-174' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-175' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-176' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-177' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-178' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-179' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-180' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-181' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-182' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-183' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Sample approximately 1% of the data\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m sampled_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m plot \u001b[38;5;241m=\u001b[39m sampled_df\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mscatter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabs_diff_longitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabs_diff_latitude\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/dask/base.py:342\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    319\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/dask/base.py:628\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 628\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/threading.py:331\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%time\n",
    "\n",
    "# Sample approximately 1% of the data\n",
    "sampled_df = train_df.sample(frac=0.01).compute()\n",
    "\n",
    "plot = sampled_df.plot.scatter('abs_diff_longitude', 'abs_diff_latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36182399",
   "metadata": {},
   "source": [
    "Wow, looks like we have some strange values here: more than 1000° of distance... There's a problem somewhere.\n",
    "\n",
    "<br>\n",
    "\n",
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "- Just get rid of the extreme values, we should keep only values inside the city wall or so. Like with Pandas above...\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e3286a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.05 ms, sys: 0 ns, total: 5.05 ms\n",
      "Wall time: 4.85 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = train_df[(train_df.abs_diff_longitude < 5) & (train_df.abs_diff_latitude < 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfc1f4a",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "- you can do another plot like above with the filtered values if you like.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45edd5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampled_df = train_df.sample(frac=0.01).compute()\n",
    "\n",
    "plot = sampled_df.plot.scatter('abs_diff_longitude', 'abs_diff_latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a525ada",
   "metadata": {},
   "source": [
    "Ok, let's see some statistics on our Dataset. The describe() function inherited from Pandas compute a lot of statistics on a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d49070ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>abs_diff_longitude</th>\n",
       "      <th>abs_diff_latitude</th>\n",
       "      <th>rounded_dropoff_latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.529894e+07</td>\n",
       "      <td>5.529894e+07</td>\n",
       "      <td>5.529894e+07</td>\n",
       "      <td>5.529894e+07</td>\n",
       "      <td>5.529894e+07</td>\n",
       "      <td>5.529894e+07</td>\n",
       "      <td>5.529894e+07</td>\n",
       "      <td>5.529894e+07</td>\n",
       "      <td>5.529894e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.133683e+01</td>\n",
       "      <td>-7.257290e+01</td>\n",
       "      <td>3.995280e+01</td>\n",
       "      <td>-7.257205e+01</td>\n",
       "      <td>3.995314e+01</td>\n",
       "      <td>1.685440e+00</td>\n",
       "      <td>2.251316e-02</td>\n",
       "      <td>2.110157e-02</td>\n",
       "      <td>4.019696e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.071499e+01</td>\n",
       "      <td>1.094742e+01</td>\n",
       "      <td>7.044005e+00</td>\n",
       "      <td>1.094731e+01</td>\n",
       "      <td>7.044055e+00</td>\n",
       "      <td>1.326790e+00</td>\n",
       "      <td>3.854502e-02</td>\n",
       "      <td>2.903143e-02</td>\n",
       "      <td>7.071860e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.000000e+02</td>\n",
       "      <td>-3.440696e+03</td>\n",
       "      <td>-3.488080e+03</td>\n",
       "      <td>-3.440696e+03</td>\n",
       "      <td>-3.488080e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.488000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>-7.399201e+01</td>\n",
       "      <td>4.073514e+01</td>\n",
       "      <td>-7.399136e+01</td>\n",
       "      <td>4.073421e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.827000e-03</td>\n",
       "      <td>6.606000e-03</td>\n",
       "      <td>4.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.500000e+00</td>\n",
       "      <td>-7.398174e+01</td>\n",
       "      <td>4.075281e+01</td>\n",
       "      <td>-7.398010e+01</td>\n",
       "      <td>4.075332e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.244900e-02</td>\n",
       "      <td>1.387000e-02</td>\n",
       "      <td>4.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.250000e+01</td>\n",
       "      <td>-7.396703e+01</td>\n",
       "      <td>4.076725e+01</td>\n",
       "      <td>-7.396365e+01</td>\n",
       "      <td>4.076821e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.370300e-02</td>\n",
       "      <td>2.697000e-02</td>\n",
       "      <td>4.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.396336e+04</td>\n",
       "      <td>3.456223e+03</td>\n",
       "      <td>3.378013e+03</td>\n",
       "      <td>3.456223e+03</td>\n",
       "      <td>3.378013e+03</td>\n",
       "      <td>2.080000e+02</td>\n",
       "      <td>4.989833e+00</td>\n",
       "      <td>4.991325e+00</td>\n",
       "      <td>3.378000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "count  5.529894e+07      5.529894e+07     5.529894e+07       5.529894e+07   \n",
       "mean   1.133683e+01     -7.257290e+01     3.995280e+01      -7.257205e+01   \n",
       "std    2.071499e+01      1.094742e+01     7.044005e+00       1.094731e+01   \n",
       "min   -3.000000e+02     -3.440696e+03    -3.488080e+03      -3.440696e+03   \n",
       "25%    6.000000e+00     -7.399201e+01     4.073514e+01      -7.399136e+01   \n",
       "50%    8.500000e+00     -7.398174e+01     4.075281e+01      -7.398010e+01   \n",
       "75%    1.250000e+01     -7.396703e+01     4.076725e+01      -7.396365e+01   \n",
       "max    9.396336e+04      3.456223e+03     3.378013e+03       3.456223e+03   \n",
       "\n",
       "       dropoff_latitude  passenger_count  abs_diff_longitude  \\\n",
       "count      5.529894e+07     5.529894e+07        5.529894e+07   \n",
       "mean       3.995314e+01     1.685440e+00        2.251316e-02   \n",
       "std        7.044055e+00     1.326790e+00        3.854502e-02   \n",
       "min       -3.488080e+03     0.000000e+00        0.000000e+00   \n",
       "25%        4.073421e+01     1.000000e+00        5.827000e-03   \n",
       "50%        4.075332e+01     1.000000e+00        1.244900e-02   \n",
       "75%        4.076821e+01     2.000000e+00        2.370300e-02   \n",
       "max        3.378013e+03     2.080000e+02        4.989833e+00   \n",
       "\n",
       "       abs_diff_latitude  rounded_dropoff_latitude  \n",
       "count       5.529894e+07              5.529894e+07  \n",
       "mean        2.110157e-02              4.019696e+01  \n",
       "std         2.903143e-02              7.071860e+00  \n",
       "min         0.000000e+00             -3.488000e+03  \n",
       "25%         6.606000e-03              4.100000e+01  \n",
       "50%         1.387000e-02              4.100000e+01  \n",
       "75%         2.697000e-02              4.100000e+01  \n",
       "max         4.991325e+00              3.378000e+03  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7ec27e",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Find some values (at least two) that still looks odd to you in the table above.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4bebbd-a2f0-45bc-98dc-dbbb78f204cb",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "The minimum fare is negative, and the maximum fare is 93,963$, which is unlikely. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84739b99",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Do you think we could parallelize things better for any of our computation or data access? (It's a trap).\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0968301b-aed0-4402-8b65-90af6565c5bd",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "Over-parallelization can introduce unnecessary overhead and complexity without proportional benefits. The goal should be to find a balance that leverages parallelism effectively while minimizing overhead and efficiently utilizing available resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead4e91",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "### BONUS Questions (you don't have to do this, just go back to it if you want to improve, skip it at first)\n",
    "\n",
    "Some other questions to practice\n",
    "\n",
    "- Can you see a correlation between the fare amount and the dropoff latitude? Answer by doing a dask dataframe computation.\n",
    "\n",
    "First you'll need to round the dropoff latitude to have some sort of categories using Series.round() function.\n",
    "\n",
    "Then, just group_by this new colon to have some answer (and don't forget to compute to get the results).\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78f631f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-372' coro=<Client._gather.<locals>.wait() done, defined at /srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:2208> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py\", line 2217, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrounded_dropoff_latitude\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropoff_latitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mround()\n\u001b[1;32m      5\u001b[0m result \u001b[38;5;241m=\u001b[39m train_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrounded_dropoff_latitude\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfare_amount\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m----> 7\u001b[0m computed_result \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m computed_result\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/dask/base.py:342\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    319\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/site-packages/dask/base.py:628\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 628\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.11/threading.py:331\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "train_df['rounded_dropoff_latitude'] = train_df['dropoff_latitude'].round()\n",
    "\n",
    "result = train_df.groupby('rounded_dropoff_latitude')['fare_amount'].mean()\n",
    "\n",
    "computed_result = result.compute()\n",
    "\n",
    "computed_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f28182",
   "metadata": {},
   "source": [
    "OK, this don't give a lot of insights, but it looks like we've got some strange values somewhere!\n",
    "\n",
    "<br>\n",
    "\n",
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "- Let's just have a look of non extreme values, so probably some records at the middle of the results.\n",
    "We need first to sort the resulting series by index before looking at the middle of it.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1430445",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computationnally too costly... made my google cloud crash multiple times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd946db2",
   "metadata": {},
   "source": [
    "OK, this is not really useful, but it's an exercise!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b40adc",
   "metadata": {},
   "source": [
    "## Training a model in a distributed way\n",
    "\n",
    "Let's begin with a linear model that we can distributed with Dask ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2e693a",
   "metadata": {},
   "source": [
    "### Building our feature vectors\n",
    "\n",
    "Here again define a method so that we can use it later for our test set evaluation.\n",
    "\n",
    "<br>\n",
    "\n",
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Just do the same as with the Pandas example by defining a get_input_matrix(df) function. But this time you'll generate a dask array (not numpy) using `to_dask_array(lengths=True)` method on the dataframe object instead of `np.column_stack` (look a bit a dask docs in order to find how to use this method). You should do a method that generate the X input features dask array, and also the same with y training results. You can do just one method that return both (return X, y). \n",
    "- It is a good idea to persist() arrays in memory in or after the call.\n",
    "- This time, we'll add the feature 'passenger_count' in addition to the distance vectors, one more feature! So X must have 3 columns.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6d6b00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 11.4 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/tornado/iostream.py\", line 1367, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/ssl.py\", line 1383, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: [SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1006)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 192, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/tornado/iostream.py\", line 691, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/tornado/iostream.py\", line 1454, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/tornado/iostream.py\", line 1376, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/tornado/iostream.py\", line 606, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/tornado/iostream.py\", line 636, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/tornado/iostream.py\", line 1367, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/ssl.py\", line 1383, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: [SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1006)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 192, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/tornado/iostream.py\", line 691, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/tornado/iostream.py\", line 1454, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/tornado/iostream.py\", line 1376, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/tornado/iostream.py\", line 606, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.11/site-packages/tornado/iostream.py\", line 636, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "\n",
    "def get_input_matrix(df):\n",
    "    features_df = df[['abs_diff_longitude', 'abs_diff_latitude', 'passenger_count']]\n",
    "    X = features_df.to_dask_array(lengths=True)\n",
    "    y = df['fare_amount'].to_dask_array(lengths=True)\n",
    "    X = X.persist()\n",
    "    y = y.persist()\n",
    "    return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aad88f",
   "metadata": {},
   "source": [
    "Then we get the values, and display train_X to have some insights of its size and chunking scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61c4eea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 1.24 GiB </td>\n",
       "                        <td> 14.23 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (55298943, 3) </td>\n",
       "                        <td> (621549, 3) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 89 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float64 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"75\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"5\" x2=\"25\" y2=\"5\" />\n",
       "  <line x1=\"0\" y1=\"12\" x2=\"25\" y2=\"12\" />\n",
       "  <line x1=\"0\" y1=\"18\" x2=\"25\" y2=\"18\" />\n",
       "  <line x1=\"0\" y1=\"24\" x2=\"25\" y2=\"24\" />\n",
       "  <line x1=\"0\" y1=\"31\" x2=\"25\" y2=\"31\" />\n",
       "  <line x1=\"0\" y1=\"37\" x2=\"25\" y2=\"37\" />\n",
       "  <line x1=\"0\" y1=\"43\" x2=\"25\" y2=\"43\" />\n",
       "  <line x1=\"0\" y1=\"49\" x2=\"25\" y2=\"49\" />\n",
       "  <line x1=\"0\" y1=\"56\" x2=\"25\" y2=\"56\" />\n",
       "  <line x1=\"0\" y1=\"62\" x2=\"25\" y2=\"62\" />\n",
       "  <line x1=\"0\" y1=\"68\" x2=\"25\" y2=\"68\" />\n",
       "  <line x1=\"0\" y1=\"75\" x2=\"25\" y2=\"75\" />\n",
       "  <line x1=\"0\" y1=\"80\" x2=\"25\" y2=\"80\" />\n",
       "  <line x1=\"0\" y1=\"87\" x2=\"25\" y2=\"87\" />\n",
       "  <line x1=\"0\" y1=\"94\" x2=\"25\" y2=\"94\" />\n",
       "  <line x1=\"0\" y1=\"99\" x2=\"25\" y2=\"99\" />\n",
       "  <line x1=\"0\" y1=\"106\" x2=\"25\" y2=\"106\" />\n",
       "  <line x1=\"0\" y1=\"113\" x2=\"25\" y2=\"113\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 25.412616514582485,0.0 25.412616514582485,120.0 0.0,120.0\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.706308\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >3</text>\n",
       "  <text x=\"45.412617\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,45.412617,60.000000)\">55298943</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<values, shape=(55298943, 3), dtype=float64, chunksize=(621549, 3), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "train_X, train_y = get_input_matrix(train_df)\n",
    "train_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16204e42",
   "metadata": {},
   "source": [
    "### Distributed training a Linear model\n",
    "\n",
    "Be careful, this can take time, try first with few iterations (Use max_iter = 5 as a kwarg to LinearRegression constructor).\n",
    "\n",
    "see https://ml.dask.org/glm.html  \n",
    "and https://ml.dask.org/modules/generated/dask_ml.linear_model.LinearRegression.html#dask_ml.linear_model.LinearRegression\n",
    "\n",
    "<br>\n",
    "\n",
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Train a LinearRegression model from dask_ml.linear_model on our inputs\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52ba9d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression(max_iter=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression(max_iter=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression(max_iter=10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Answer needed here\n",
    "%time\n",
    "from dask_ml.linear_model import LinearRegression\n",
    "model = LinearRegression(max_iter=10)\n",
    "model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65ec13f",
   "metadata": {},
   "source": [
    "## Evaluating our model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b3b96f",
   "metadata": {},
   "source": [
    "#### First we should load the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e78929e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>abs_diff_longitude</th>\n",
       "      <th>abs_diff_latitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int64</td>\n",
       "      <td>string</td>\n",
       "      <td>float64</td>\n",
       "      <td>string</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: to_pyarrow_string, 2 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              Unnamed: 0     key fare_amount pickup_datetime pickup_longitude pickup_latitude dropoff_longitude dropoff_latitude passenger_count abs_diff_longitude abs_diff_latitude\n",
       "npartitions=1                                                                                                                                                                        \n",
       "                   int64  string     float64          string          float64         float64           float64          float64           int64            float64           float64\n",
       "                     ...     ...         ...             ...              ...             ...               ...              ...             ...                ...               ...\n",
       "Dask Name: to_pyarrow_string, 2 graph layers"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = dd.read_csv('gs://obd-dask23/test_cleaned.csv', storage_options={'token': 'anon'})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0695ac",
   "metadata": {},
   "source": [
    "Adding our features to the test set and getting our feature array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2432c8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 233.74 kiB </td>\n",
       "                        <td> 233.74 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (9973, 3) </td>\n",
       "                        <td> (9973, 3) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 1 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float64 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"75\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 25.412616514582485,0.0 25.412616514582485,120.0 0.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.706308\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >3</text>\n",
       "  <text x=\"45.412617\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,45.412617,60.000000)\">9973</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<values, shape=(9973, 3), dtype=float64, chunksize=(9973, 3), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_travel_vector_features(test_df)\n",
    "test_X, test_y = get_input_matrix(test_df)\n",
    "test_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245a45fa",
   "metadata": {},
   "source": [
    "We can use the score method inherited from Scikit learn, it gives some hints on the model performance (but our scoring board will be on RMSE). Even if for linear models, score if often low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0bc8e4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5445292448669485"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "65be4dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31.94932154, 10.4277079 , 13.41553028, ...,  8.44994263,\n",
       "       10.06444395,  7.22275752])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_X).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56e0b52",
   "metadata": {},
   "source": [
    "#### Compute the RMSE\n",
    "\n",
    "https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/overview/evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c12a254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.418952655682574"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(test_y.compute(), model.predict(test_X).compute(), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618691b3",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- What RMSE did you get? Compare it to the Pandas only computation.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f170c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We get a 6.41 RMSE, this is not bad at all considering 5 iterations only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c75934",
   "metadata": {},
   "source": [
    "# Distributed XGboost (optionnal, you can skip it at first)\n",
    "\n",
    "Just use the documentation here https://xgboost.readthedocs.io/en/stable/tutorials/dask.html#overview to train a model on this dataset using xgboost.\n",
    "\n",
    "<br>\n",
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Just copy/paste the example (dtrain = ..., output = ...), and modify some input variables.\n",
    "- Then make a prediction (but don't forget to use your test set, not as in the prediction = ... example from the Xgboost doc).\n",
    "- Compute the mean square error on it.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c158497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.dask.DaskDMatrix(client, train_X, train_y)\n",
    "output = xgb.dask.train(\n",
    "    client,\n",
    "    {\"verbosity\": 2, \"tree_method\": \"hist\", \"objective\": \"reg:squarederror\"},\n",
    "    dtrain,\n",
    "    num_boost_round=4,\n",
    "    evals=[(dtrain, \"train\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c42822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.dask.DaskDMatrix(client, test_X, test_y)\n",
    "prediction = xgb.dask.predict(client, output, dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b580369c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.062154804026349"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(test_y.compute(), prediction.compute(), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993d1443",
   "metadata": {},
   "source": [
    "## Use Dask to scale computation on Hyper Parameter Search\n",
    "\n",
    "As seen above, Dask is well suited to distribute Data and learn a model on a big Data set. However, not all the models can be trained in parallel on sub chunks of Data. See https://scikit-learn.org/stable/computing/scaling_strategies.html for the compatible models of Scikit learn for example.\n",
    "\n",
    "Dask can also be used to train several models in parallel on small datasets, this is what we'll try now.\n",
    "\n",
    "We will just take a sample of the training set, and try to learn several models with different hyper parameters, and find the best one.\n",
    "\n",
    "Dask Hyper parameter search : https://ml.dask.org/hyper-parameter-search.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc0e7a",
   "metadata": {},
   "source": [
    "First we'll take a small subset of the Data, 5% is a maximum if we want to avoir memory issues on our workers and have appropriate training times. You can try with less if the results are still good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5c06652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a sample of the input data, get it as pandas dataframe\n",
    "train_sample_df = train_df.sample(frac=0.05, random_state=270120)\n",
    "# Get feature vectors out of it\n",
    "train_sample_X, train_sample_y = get_input_matrix(train_sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c03fe60",
   "metadata": {},
   "source": [
    "In order to optimize things, we can also change the type of the features to more appropriate and small types.\n",
    "\n",
    "We also need to use Numpy arrays, so we'll gather the result from Dask to local variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fdee85b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3080e-03, 6.3600e-03, 1.0000e+00],\n",
       "       [2.0610e-03, 2.6387e-02, 2.0000e+00],\n",
       "       [1.7517e-02, 2.4680e-03, 1.0000e+00],\n",
       "       ...,\n",
       "       [7.2300e-04, 4.1070e-03, 1.0000e+00],\n",
       "       [7.2100e-04, 1.6487e-02, 1.0000e+00],\n",
       "       [1.6892e-02, 5.4378e-02, 1.0000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample_X = train_sample_X.astype('float32').compute()\n",
    "train_sample_y = train_sample_y.astype('float32').compute()\n",
    "train_sample_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6971e4a",
   "metadata": {},
   "source": [
    "What size is our dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d9bf7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33179432"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(train_sample_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f2ee9",
   "metadata": {},
   "source": [
    "About 32MB, this is still quite a big dataset for standard machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1a4fc2",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "- Now, just use hyper parameter search Dask API to distribute the search. You can either use joblib integration with Sklearn or dask_ml directly. \n",
    "\n",
    "**Be careful: do not use model too long to train, and limit their complexity at first or the combinations of hyper parameters you'll use. Hint, start first with a simple LinearModel like SGDRegressor and not more than 10 iterations per model.**\n",
    "</span>\n",
    "\n",
    "So start with something like:\n",
    "\n",
    "- RandomizedSearchCV https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html, with cv=2, n_iter=50, verbose=10\n",
    "- With sklearn.linear_model.SGDRegressor with max_iter=20\n",
    "- Use this parameter space:\n",
    "```python\n",
    "from scipy.stats import uniform, loguniform\n",
    "param_space = {\n",
    "    \"average\": [True, False],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    \"alpha\": loguniform(1e-5, 1e-1),\n",
    "    \"learning_rate\": [\"invscaling\", \"adaptive\"],\n",
    "    \"power_t\": uniform(0, 1),\n",
    "}\n",
    "```\n",
    "- If you chose sklearn API, you want to import joblib, and use `with joblib.parallel_backend('dask'):` before fitting your model.\n",
    "- If you chose dask_ml API, https://ml.dask.org/hyper-parameter-search.html#basic-use, you'll don't need the with syntax, but just the correct imports: from dask_ml.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d3732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Answer needed here (with sklearn API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc43a312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 42.20 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 42.19 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 6.410277188110155e-05, 'average': False, 'learning_rate': 'invscaling', 'penalty': 'l2', 'power_t': 0.3143559810763267}\n",
      "Best score: 0.503800491630873\n",
      "CPU times: user 570 ms, sys: 216 ms, total: 785 ms\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from dask_ml.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from scipy.stats import uniform, loguniform\n",
    "\n",
    "# Define the parameter space\n",
    "param_space = {\n",
    "    \"average\": [True, False],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    \"alpha\": loguniform(1e-5, 1e-1),\n",
    "    \"learning_rate\": [\"invscaling\", \"adaptive\"],\n",
    "    \"power_t\": uniform(0, 1),\n",
    "}\n",
    "\n",
    "# Initialize the SGDRegressor\n",
    "model = SGDRegressor(max_iter=20)\n",
    "\n",
    "# Set up the randomized search with cross-validation\n",
    "search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_space,\n",
    "    n_iter=50,\n",
    "    cv=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Perform the search on the sampled data\n",
    "# Assuming train_sample_X and train_sample_y are already computed and converted to pandas DataFrame/series\n",
    "search.fit(train_sample_X, train_sample_y)\n",
    "\n",
    "# Results\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "print(\"Best score:\", search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5dcf013b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5477293631050179"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0cf1ae20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.396363262943413"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(test_y, search.predict(test_X), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8545454",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "- So how does this result compare to the previous one we got with a distributed leaning with a linear model on all the dataset?\n",
    "    \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db09016-2251-4ffa-a8f4-df5ed3f9d31b",
   "metadata": {},
   "source": [
    "**ANSWER** \n",
    "\n",
    "Our RMSE is slightly better, like the accuracy, but the difference is not very shocking. Maybe we should run a more ambitious GridSearch and increase the number of iterations to see a real difference. XGBoost, however, was much more efficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661cfe73",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "\n",
    "- Try with https://ml.dask.org/modules/generated/dask_ml.model_selection.HyperbandSearchCV.html#dask_ml.model_selection.HyperbandSearchCV instead of RandomizedSearchCV.\n",
    "    \n",
    "You'd prefer to use dask_ml.model_selection.HyperbandSearchCV (instead of joblib). And just need to change n_iter to max_iter, and remove another arg.\n",
    "    \n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f223ae96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 42.19 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'power_t': 0.1, 'penalty': 'l1', 'learning_rate': 'adaptive', 'average': True, 'alpha': 1e-05}\n",
      "Best score: 0.5114013035648637\n",
      "CPU times: user 881 ms, sys: 577 ms, total: 1.46 s\n",
      "Wall time: 51.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from dask_ml.model_selection import HyperbandSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "model = SGDRegressor(max_iter=20)\n",
    "#Unfortunately, uniform distribution are not supported here\n",
    "param_space = {\n",
    "    'average': [True, False],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'alpha': [1e-5, 1e-3, 1e-1],  \n",
    "    'learning_rate': ['invscaling', 'adaptive'],\n",
    "    'power_t': [0.1, 0.3, 0.5] }\n",
    "\n",
    "search = HyperbandSearchCV(\n",
    "    model,\n",
    "    param_space,\n",
    "    max_iter=50,\n",
    "    patience=True,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "search.fit(train_sample_X, train_sample_y)\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "print(\"Best score:\", search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b489ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5430723048471259"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f90d9c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.429210792045596"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(test_y, search.predict(test_X), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9592bec",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- OK, Linear models are what they are, we'll try to do better with Random forest! https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "    \n",
    "Return to RandomizedSearchCV for now.\n",
    "\n",
    "Caution: use limited trees, small number of estimators < 10 and max_depth < 40 at first\n",
    "</span>\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "param_space = {\n",
    "'n_estimators': range(4,10),\n",
    "'max_depth': range(10,40),\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fcc66ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 42.19 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 42.19 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 7, 'max_depth': 11}\n",
      "Best score: 0.7440967136079293\n"
     ]
    }
   ],
   "source": [
    "from dask_ml.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import dask.array as da\n",
    "\n",
    "# Define the parameter space\n",
    "param_space = {\n",
    "    'n_estimators': range(4, 10),  # Fewer estimators for quicker iterations\n",
    "    'max_depth': range(10, 40),    # Limited depth to prevent overly complex models initially\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Setup Randomized Search with cross-validation\n",
    "search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_space,\n",
    "    n_iter=50,  \n",
    "    cv=2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "search.fit(train_sample_X, train_sample_y)\n",
    "\n",
    "# Print the results\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "print(\"Best score:\", search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cd8318",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- If you did not used joblib, try it now.\n",
    "\n",
    "What do you observe when training RandomForest tree on Dask parallelization Dashboard with joblib? Can you explain why there are so many tasks?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6dee3a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n",
      "Best parameters: {'n_estimators': 7, 'max_depth': 11}\n",
      "Best score: 0.7446222701628291\n",
      "CPU times: user 1.48 s, sys: 448 ms, total: 1.92 s\n",
      "Wall time: 12min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from dask.distributed import Client\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from joblib import parallel_backend\n",
    "\n",
    "# Define the parameter space\n",
    "param_space = {\n",
    "    'n_estimators': range(4, 10), \n",
    "    'max_depth': range(10, 40),\n",
    "}\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_space,\n",
    "    n_iter=50,\n",
    "    cv=2,\n",
    "    random_state=42,\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "# Use Dask's Joblib backend to distribute the computation\n",
    "with parallel_backend('dask'):\n",
    "    search.fit(train_sample_X, train_sample_y)\n",
    "\n",
    "# Print the results\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "print(\"Best score:\", search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35a398ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.773020008600353"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e72798f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.531351078089515"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(test_y, search.predict(test_X), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fba8bc",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "- Did you get better results with RandomForest? Do you know why?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39708a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Much better score (74% accuracy with ml, and 77% with joblib) ! \n",
    "##I assume that the distribution of the data highly non-linear, since random forest use to perform well on non-linear data distribution\n",
    "#I reached an RMSE of 4.53, which is pretty close to 4.5 !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83862a8",
   "metadata": {},
   "source": [
    "<span style=\"color:#EB5E0B;font-style:italic\">\n",
    "    \n",
    "# Extend this notebook\n",
    "    \n",
    "With the example aboves, I reached a score of about 4.5 RMSE. Try to do better!\n",
    "\n",
    "- Add new features to the input Data using Dask Dataframes, or clean it better. Reapply the learning above with these new features. Do you get better results? Some suggestions for a better leaning:\n",
    "  - Try to clean extremes or non realistic values you identified above in the training set.\n",
    "  - Apply some normalisation or regularization or other feature transformation? See https://ml.dask.org/preprocessing.html.\n",
    "  - Add some non linear features (square feature, for example square the travel vector)\n",
    "  - Maybe the hour of the day, or the month, has some impact on fares? Try to add features. See https://matthewrocklin.com/blog/work/2017/01/12/dask-dataframes for some hints on how to do this.\n",
    "  - Maybe try to find a way to use the start and drop off locations?\n",
    "- Improve the model parameters or find a better one. Try using this time dask_ml HyperbandSearchCV. See https://ml.dask.org/hyper-parameter-search.html#basic-use. You can use it for example with https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor.\n",
    "- Try one single RandomForestRegressor (with no HyperParameterSearch), but with big depth and estimators. This single model fitting should be distributed on dask with joblib (Random Forest is about training several decision trees).\n",
    "\n",
    "</span>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
